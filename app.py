import streamlit as st
import pandas as pd
import numpy as np
import re
import unicodedata
import requests
from io import BytesIO
import plotly.express as px

# --- Helper functions ---
def remove_accents(input_str):
    nfkd = unicodedata.normalize('NFKD', input_str)
    return "".join(c for c in nfkd if not unicodedata.combining(c))

def norm(s: str) -> str:
    s = remove_accents(str(s)).lower().strip()
    return re.sub(r"\s+", " ", s)

def find_header_row(df: pd.DataFrame, keywords: list):
    for i in range(10):
        row = " ".join(df.iloc[i].fillna("").astype(str)).lower()
        if all(k in row for k in keywords):
            return i
    return None

@st.cache_data
def load_default_data():
    url2 = "https://raw.githubusercontent.com/phamtai1211/Thau_3PPharma/main/file2.xlsx"
    url3 = "https://raw.githubusercontent.com/phamtai1211/Thau_3PPharma/main/file3.xlsx"
    url4 = "https://raw.githubusercontent.com/phamtai1211/Thau_3PPharma/main/nhom_dieu_tri.xlsx"
    f2 = pd.read_excel(BytesIO(requests.get(url2).content))
    f3 = pd.read_excel(BytesIO(requests.get(url3).content))
    f4 = pd.read_excel(BytesIO(requests.get(url4).content))
    return f2, f3, f4

# Load data
file2, file3, file4 = load_default_data()

# Filter file3: lo·∫°i b·ªè "t·∫°m ng∆∞ng tri·ªÉn khai" & "ko c√≥ ƒë·ªãa b√†n"
file3["ƒê·ªãa b√†n"] = file3["ƒê·ªãa b√†n"].fillna("")
file3_filtered = file3[~file3["ƒê·ªãa b√†n"].str.contains("t·∫°m ng∆∞ng tri·ªÉn khai|ko c√≥ ƒë·ªãa b√†n", case=False)]
st.session_state["file3_filtered"] = file3_filtered

# Sidebar
st.sidebar.title("Ch·ª©c nƒÉng")
option = st.sidebar.radio("Ch·ªçn ch·ª©c nƒÉng", [
    "L·ªçc Danh M·ª•c Th·∫ßu",
    "Ph√¢n T√≠ch Danh M·ª•c Th·∫ßu",
    "Ph√¢n T√≠ch Danh M·ª•c Tr√∫ng Th·∫ßu",
    "ƒê·ªÅ Xu·∫•t H∆∞·ªõng Tri·ªÉn Khai",
    "Tra Cuu Hoat Chat"
])

# 1. L·ªçc Danh M·ª•c Th·∫ßu
if option == "L·ªçc Danh M·ª•c Th·∫ßu":
    st.header("üìÇ L·ªçc Danh M·ª•c Th·∫ßu")
    # Select region/area/province/hospital
    df3 = file3_filtered.copy()
    regions = ["(T·∫•t c·∫£)"] + sorted(df3["Mi·ªÅn"].dropna().unique().tolist())
    r = st.selectbox("Ch·ªçn Mi·ªÅn", regions)
    if r != "(T·∫•t c·∫£)": df3 = df3[df3["Mi·ªÅn"]==r]
    areas = ["(T·∫•t c·∫£)"] + sorted(df3["V√πng"].dropna().unique().tolist())
    a = st.selectbox("Ch·ªçn V√πng", areas)
    if a != "(T·∫•t c·∫£)": df3 = df3[df3["V√πng"]==a]
    provs = ["(T·∫•t c·∫£)"] + sorted(df3["T·ªânh"].dropna().unique().tolist())
    p = st.selectbox("Ch·ªçn T·ªânh", provs)
    if p != "(T·∫•t c·∫£)": df3 = df3[df3["T·ªânh"]==p]
    h = st.selectbox("Ch·ªçn B·ªánh vi·ªán/SYT", sorted(df3["B·ªánh vi·ªán/SYT"].dropna().unique().tolist()))

    uploaded = st.file_uploader("File Danh M·ª•c M·ªùi Th·∫ßu (.xlsx)", type="xlsx")
    if uploaded is None:
        st.info("Vui l√≤ng t·∫£i l√™n file M·ªùi Th·∫ßu.")
        st.stop()

    # Read sheet with most columns
    xls = pd.ExcelFile(uploaded)
    sheet = max(xls.sheet_names, key=lambda n: xls.parse(n, nrows=1, header=None).shape[1])
    raw = pd.read_excel(uploaded, sheet_name=sheet, header=None)
    hdr = find_header_row(raw, ["t√™n ho·∫°t ch·∫•t","s·ªë l∆∞·ª£ng"])
    if hdr is None:
        st.error("Kh√¥ng t√¨m th·∫•y header trong 10 d√≤ng ƒë·∫ßu.")
        st.stop()

    header = raw.iloc[hdr].tolist()
    df_all = raw.iloc[hdr+1:].copy().reset_index(drop=True)
    df_all.columns = header
    df_all = df_all.dropna(how="all").reset_index(drop=True)

    # Normalize keys
    df_all["_act"] = df_all["T√™n ho·∫°t ch·∫•t"].apply(norm)
    col_conc = "N·ªìng ƒë·ªô/h√†m l∆∞·ª£ng" if "N·ªìng ƒë·ªô/h√†m l∆∞·ª£ng" in df_all.columns else "N·ªìng ƒë·ªô/H√†m l∆∞·ª£ng"
    df_all["_conc"] = df_all[col_conc].apply(norm)
    df_all["_grp"]  = df_all["Nh√≥m thu·ªëc"].astype(str).apply(lambda x: re.sub(r"\D","",x))

    df_cmp = file2.copy()
    df_cmp["_act"]  = df_cmp["T√™n ho·∫°t ch·∫•t"].apply(norm)
    df_cmp["_conc"] = df_cmp["N·ªìng ƒë·ªô/H√†m l∆∞·ª£ng"].apply(norm)
    df_cmp["_grp"]  = df_cmp["Nh√≥m thu·ªëc"].astype(str).apply(lambda x: re.sub(r"\D","",x))

    # Left merge to keep all df_all rows
    merged = pd.merge(df_all, df_cmp,
                      on=["_act","_conc","_grp"],
                      how="left", suffixes=("","_cmp"))

    # Attach branding & hospital info
    info3 = file3_filtered[file3_filtered["B·ªánh vi·ªán/SYT"]==h][
        ["T√™n s·∫£n ph·∫©m","ƒê·ªãa b√†n","T√™n Kh√°ch h√†ng ph·ª• tr√°ch tri·ªÉn khai"]].drop_duplicates()
    merged = pd.merge(merged, info3, on="T√™n s·∫£n ph·∫©m", how="left")

    # Compute T·ª∑ tr·ªçng nh√≥m th·∫ßu
    merged["S·ªë l∆∞·ª£ng"] = pd.to_numeric(merged.get("S·ªë l∆∞·ª£ng",0),errors="coerce").fillna(0)
    grp_sum = merged.groupby("Nh√≥m thu·ªëc")["S·ªë l∆∞·ª£ng"].transform("sum")
    merged["T·ª∑ tr·ªçng nh√≥m th·∫ßu"] = (merged["S·ªë l∆∞·ª£ng"]/grp_sum).fillna(0).apply(lambda x:f"{x:.2%}")

    # Save for analysis
    st.session_state["filtered_df"] = merged
    st.session_state["df_all_session"] = df_all  # to√†n b·ªô file1 data

    st.success(f"‚úÖ ƒê√£ l·ªçc xong {len(merged)} d√≤ng.")
    st.dataframe(merged, height=600)

    buf = BytesIO()
    merged.to_excel(buf, index=False, sheet_name="KetQuaLoc")
    st.download_button("‚¨áÔ∏è T·∫£i v·ªÅ k·∫øt qu·∫£", data=buf.getvalue(),file_name="KetQuaLoc.xlsx")

# 2. Ph√¢n T√≠ch Danh M·ª•c Th·∫ßu
elif option == "Ph√¢n T√≠ch Danh M·ª•c Th·∫ßu":
    st.header("üìä Ph√¢n T√≠ch Danh M·ª•c Th·∫ßu")
    if "df_all_session" not in st.session_state:
        st.info("Ch·∫°y L·ªçc Danh M·ª•c Th·∫ßu tr∆∞·ªõc.")
        st.stop()
    df_all = st.session_state["df_all_session"].copy()
    df_all["S·ªë l∆∞·ª£ng"] = pd.to_numeric(df_all["S·ªë l∆∞·ª£ng"],errors="coerce").fillna(0)
    df_all["Gi√° k·∫ø ho·∫°ch"] = pd.to_numeric(df_all.get("Gi√° k·∫ø ho·∫°ch",0),errors="coerce").fillna(0)
    df_all["Tr·ªã gi√°"] = df_all["S·ªë l∆∞·ª£ng"] * df_all["Gi√° k·∫ø ho·∫°ch"]

    # Nh√≥m ƒëi·ªÅu tr·ªã theo ƒê∆∞·ªùng d√πng
    def route(x):
        s=str(x).lower()
        if "ti√™m" in s: return "Ti√™m"
        if "u·ªëng" in s: return "U·ªëng"
        return "Kh√°c"
    df_all["ƒê∆∞·ªùng"] = df_all.get("ƒê∆∞·ªùng d√πng",df_all.get("Lo·∫°i ƒë∆∞·ªùng d√πng","")).apply(route)

    # Chart: Tr·ªã gi√° theo Nh√≥m thu·ªëc
    gv = df_all.groupby("Nh√≥m thu·ªëc")["Tr·ªã gi√°"].sum().reset_index().sort_values("Tr·ªã gi√°",ascending=False)
    fig = px.bar(gv, x="Nh√≥m thu·ªëc", y="Tr·ªã gi√°", title="Tr·ªã gi√° theo Nh√≥m thu·ªëc")
    fig.update_traces(texttemplate="%{y:.2s}", textposition="outside")
    st.plotly_chart(fig, use_container_width=True)

    # Chart: Tr·ªã gi√° theo ƒê∆∞·ªùng d√πng
    gv2= df_all.groupby("ƒê∆∞·ªùng")["Tr·ªã gi√°"].sum().reset_index()
    fig2= px.bar(gv2, x="ƒê∆∞·ªùng", y="Tr·ªã gi√°", title="Tr·ªã gi√° theo ƒê∆∞·ªùng d√πng")
    fig2.update_traces(texttemplate="%{y:.2s}", textposition="outside")
    st.plotly_chart(fig2, use_container_width=True)

    # Top Ho·∫°t ch·∫•t
    topA= df_all.groupby("T√™n ho·∫°t ch·∫•t")["S·ªë l∆∞·ª£ng"].sum().reset_index().sort_values("S·ªë l∆∞·ª£ng",ascending=False).head(10)
    fig3= px.bar(topA, x="T√™n ho·∫°t ch·∫•t",y="S·ªë l∆∞·ª£ng",title="Top 10 ho·∫°t ch·∫•t (SL)")
    fig3.update_traces(texttemplate="%{y:.0f}", textposition="outside")
    st.plotly_chart(fig3,use_container_width=True)

    # Nh√≥m ƒëi·ªÅu tr·ªã
    treat_map = {norm(a):g for a,g in zip(file4["Ho·∫°t ch·∫•t"],file4["Nh√≥m ƒëi·ªÅu tr·ªã"])}
    df_all["Nh√≥m ƒëi·ªÅu tr·ªã"] = df_all["T√™n ho·∫°t ch·∫•t"].apply(lambda x: treat_map.get(norm(x),"Kh√°c"))
    tv = df_all.groupby("Nh√≥m ƒëi·ªÅu tr·ªã")["Tr·ªã gi√°"].sum().reset_index().sort_values("Tr·ªã gi√°",ascending=False)
    fig4= px.bar(tv, x="Nh√≥m ƒëi·ªÅu tr·ªã", y="Tr·ªã gi√°", orientation='h',title="Tr·ªã gi√° theo Nh√≥m ƒëi·ªÅu tr·ªã")
    fig4.update_traces(texttemplate="%{x:.2s}", textposition="outside")
    st.plotly_chart(fig4,use_container_width=True)

# 3. Ph√¢n T√≠ch Danh M·ª•c Tr√∫ng Th·∫ßu
elif option == "Ph√¢n T√≠ch Danh M·ª•c Tr√∫ng Th·∫ßu":
    st.header("üèÜ Ph√¢n T√≠ch Danh M·ª•c Tr√∫ng Th·∫ßu")
    win = st.file_uploader("File K·∫øt qu·∫£ Tr√∫ng Th·∫ßu", type="xlsx")
    if win is None:
        st.info("H√£y t·∫£i file Tr√∫ng Th·∫ßu l√™n.")
        st.stop()
    xlsw = pd.ExcelFile(win)
    sheetw = max(xlsw.sheet_names, key=lambda n: xlsw.parse(n,nrows=1,header=None).shape[1])
    raww = pd.read_excel(win, sheet_name=sheetw, header=None)
    hi = find_header_row(raww, ["t√™n ho·∫°t ch·∫•t","nh√† th·∫ßu tr√∫ng"])
    if hi is None:
        st.error("Kh√¥ng t√¨m header tr√∫ng th·∫ßu.")
        st.stop()
    hdrw = raww.iloc[hi].tolist()
    dfw = raww.iloc[hi+1:].copy().reset_index(drop=True)
    dfw.columns=hdrw
    dfw=dfw.dropna(how="all").reset_index(drop=True)
    dfw["S·ªë l∆∞·ª£ng"] = pd.to_numeric(dfw.get("S·ªë l∆∞·ª£ng",0),errors="coerce").fillna(0)
    price_col = next((c for c in dfw.columns if "Gi√° tr√∫ng" in c), "Gi√° k·∫ø ho·∫°ch")
    dfw[price_col]=pd.to_numeric(dfw.get(price_col,0),errors="coerce").fillna(0)
    dfw["Tr·ªã gi√°"]=dfw["S·ªë l∆∞·ª£ng"]*dfw[price_col]

    wv = dfw.groupby("Nh√† th·∫ßu tr√∫ng")["Tr·ªã gi√°"].sum().reset_index().sort_values("Tr·ªã gi√°",ascending=False).head(20)
    f1=px.bar(wv, x="Tr·ªã gi√°",y="Nh√† th·∫ßu tr√∫ng",orientation='h',title="Top 20 nh√† th·∫ßu tr√∫ng")
    f1.update_traces(texttemplate="%{x:.2s}",textposition="outside")
    st.plotly_chart(f1,use_container_width=True)

    dfw["Nh√≥m ƒëi·ªÅu tr·ªã"] = dfw["T√™n ho·∫°t ch·∫•t"].apply(lambda x: treat_map.get(norm(x),"Kh√°c"))
    tw = dfw.groupby("Nh√≥m ƒëi·ªÅu tr·ªã")["Tr·ªã gi√°"].sum().reset_index()
    f2=px.pie(tw,names="Nh√≥m ƒëi·ªÅu tr·ªã",values="Tr·ªã gi√°",title="C∆° c·∫•u tr·ªã gi√° tr√∫ng th·∫ßu")
    st.plotly_chart(f2,use_container_width=True)

# 4. ƒê·ªÅ Xu·∫•t H∆∞·ªõng Tri·ªÉn Khai
elif option == "ƒê·ªÅ Xu·∫•t H∆∞·ªõng Tri·ªÉn Khai":
    st.header("üí° ƒê·ªÅ Xu·∫•t H∆∞·ªõng Tri·ªÉn Khai")
    if "filtered_df" not in st.session_state:
        st.info("Ch·∫°y L·ªçc Danh M·ª•c Th·∫ßu tr∆∞·ªõc.")
        st.stop()
    dfm = st.session_state["filtered_df"]
    # T·ªïng SL ƒë√£ l√†m theo HC/HML/NT
    sl_done = dfm.groupby(["_act","_conc","_grp"])["S·ªë l∆∞·ª£ng"].sum().reset_index().rename(columns={"S·ªë l∆∞·ª£ng":"SL_ƒê√£ l√†m"})
    # T·ªïng SL BV c·∫ßn (t·ª´ file3_filtered)
    sl_req = file3_filtered.copy()
    sl_req["_act"]=sl_req["T√™n ho·∫°t ch·∫•t"].apply(norm)
    sl_req["_conc"]=sl_req[col_conc].apply(norm)
    sl_req["_grp"]=sl_req["Nh√≥m thu·ªëc"].astype(str).apply(lambda x: re.sub(r"\D","",x))
    sl_req = sl_req.groupby(["_act","_conc","_grp"])["S·ªë l∆∞·ª£ng"].sum().reset_index().rename(columns={"S·ªë l∆∞·ª£ng":"SL_BV"})
    # Gh√©p
    sug = pd.merge(sl_req, sl_done, on=["_act","_conc","_grp"], how="left")
    sug["SL_ƒê√£ l√†m"] = sug["SL_ƒê√£ l√†m"].fillna(0).astype(int)
    sug["ƒê·ªÅ xu·∫•t"]= (sug["SL_BV"] - sug["SL_ƒê√£ l√†m"]).clip(lower=0).astype(int)
    # Th√™m Kh√°ch h√†ng
    kh = file3_filtered[["_act","_conc","_grp","T√™n Kh√°ch h√†ng ph·ª• tr√°ch tri·ªÉn khai"]]
    kh["_act"]=kh["T√™n ho·∫°t ch·∫•t"].apply(norm)
    kh[col_conc]=kh[col_conc].apply(norm)
    kh["_grp"]=kh["Nh√≥m thu·ªëc"].astype(str).apply(lambda x: re.sub(r"\D","",x))
    kh = kh.groupby(["_act","_conc","_grp"])["T√™n Kh√°ch h√†ng ph·ª• tr√°ch tri·ªÉn khai"].first().reset_index()
    sug = sug.merge(kh, on=["_act","_conc","_grp"], how="left")

    st.subheader("üì¶ B·∫£ng ƒë·ªÅ xu·∫•t c∆° s·ªë th·∫ßu t·ªõi")
    st.dataframe(sug, height=500)

# 5. Tra c·ª©u ho·∫°t ch·∫•t
elif option == "Tra Cuu Hoat Chat":
    st.header("üîç Tra c·ª©u ho·∫°t ch·∫•t")
    term = st.text_input("Nh·∫≠p ho·∫°t ch·∫•t")
    if term:
        out = file4[file4["Ho·∫°t ch·∫•t"].str.contains(term, case=False, na=False)]
        if out.empty:
            st.warning("Kh√¥ng t√¨m th·∫•y.")
        else:
            st.dataframe(out)
