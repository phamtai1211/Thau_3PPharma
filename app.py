import streamlit as st
import pandas as pd
import numpy as np
import re
import requests
from io import BytesIO
import plotly.express as px

# --- HELPER FUNCTIONS ---

def find_header(df, keywords, max_rows=20):
    # forward-fill to handle merged cells
    df_ff = df.ffill(axis=0)
    for i in range(min(max_rows, len(df_ff))):
        row = " ".join(df_ff.iloc[i].astype(str).str.lower().str.strip().tolist())
        if all(k.lower() in row for k in keywords):
            return i
    return None


def normalize_active(name):
    s = re.sub(r"\(.*?\)", "", str(name))
    s = re.sub(r"\s+", " ", s).strip().lower()
    return s


def normalize_conc(conc):
    s = str(conc).lower().replace(',', '.')
    s = s.replace('dung t√≠ch','')
    parts = [p.strip() for p in s.split(',') if p.strip()]
    parts = [p for p in parts if re.search(r"\d", p)]
    if len(parts)>=2 and re.search(r"(mg|mcg|g|%)", parts[0]) and 'ml' in parts[-1] and '/' not in parts[0]:
        return parts[0].replace(' ','') + '/' + parts[-1].replace(' ','')
    return ''.join(p.replace(' ','') for p in parts)


def normalize_group(grp):
    return re.sub(r"\D", "", str(grp)).strip()


# --- LOAD DEFAULT DATA ---
@st.cache_data
def load_defaults():
    urls = {
        'file2': 'https://raw.githubusercontent.com/phamtai1211/Thau_3PPharma/main/file2.xlsx',
        'file3': 'https://raw.githubusercontent.com/phamtai1211/Thau_3PPharma/main/file3.xlsx',
        'file4': 'https://raw.githubusercontent.com/phamtai1211/Thau_3PPharma/main/nhom_dieu_tri.xlsx'
    }
    file2 = pd.read_excel(BytesIO(requests.get(urls['file2']).content))
    file3 = pd.read_excel(BytesIO(requests.get(urls['file3']).content))
    file4 = pd.read_excel(BytesIO(requests.get(urls['file4']).content))
    return file2, file3, file4

file2, file3, file4 = load_defaults()

# filter file3
file3 = file3[~file3['ƒê·ªãa b√†n'].astype(str).str.contains("t·∫°m ng∆∞ng tri·ªÉn khai|ko c√≥ ƒë·ªãa b√†n", case=False, na=False)]

# Sidebar
st.sidebar.title('Ch·ª©c nƒÉng')
option = st.sidebar.radio('Ch·ªçn ch·ª©c nƒÉng', [
    'L·ªçc Danh M·ª•c Th·∫ßu',
    'Ph√¢n T√≠ch Danh M·ª•c Th·∫ßu',
    'Ph√¢n T√≠ch Danh M·ª•c Tr√∫ng Th·∫ßu',
    'ƒê·ªÅ Xu·∫•t H∆∞·ªõng Tri·ªÉn Khai',
    'Tra c·ª©u ho·∫°t ch·∫•t'
])

# --- 1. FILTER TENDER ---
if option=='L·ªçc Danh M·ª•c Th·∫ßu':
    st.header('üìÇ L·ªçc Danh M·ª•c Th·∫ßu')
    # ch·ªçn b·ªánh vi·ªán
    regions = file3['Mi·ªÅn'].dropna().unique().tolist()
    sel_r = st.selectbox('Mi·ªÅn', sorted(regions))
    df3a = file3[file3['Mi·ªÅn']==sel_r]
    areas = df3a['V√πng'].dropna().unique().tolist()
    sel_a = st.selectbox('V√πng', ['(T·∫•t c·∫£)']+sorted(areas))
    if sel_a!='(T·∫•t c·∫£)': df3a = df3a[df3a['V√πng']==sel_a]
    provs = df3a['T·ªânh'].dropna().unique().tolist()
    sel_p = st.selectbox('T·ªânh', sorted(provs))
    df3a = df3a[df3a['T·ªânh']==sel_p]
    hosp = st.selectbox('BV/SYT', df3a['B·ªánh vi·ªán/SYT'].dropna().unique().tolist())

    upload = st.file_uploader('File M·ªùi Th·∫ßu', type=['xlsx'])
    if upload:
        xls = pd.ExcelFile(upload)
        # pick sheet with most cols
        sheet = max(xls.sheet_names, key=lambda s: xls.parse(s,nrows=1,header=None).shape[1])
        raw = pd.read_excel(upload, sheet_name=sheet, header=None)
        hi = find_header(raw, ['t√™n ho·∫°t ch·∫•t','s·ªë l∆∞·ª£ng'], max_rows=20)
        if hi is None:
            st.error('Kh√¥ng t√¨m th·∫•y header trong 20 d√≤ng ƒë·∫ßu.')
        else:
            df = raw.ffill(axis=0)
            df = df.iloc[hi+1:]
            df.columns = raw.iloc[hi]
            df = df.reset_index(drop=True)
            # normalize cols
            df['_act'] = df['T√™n ho·∫°t ch·∫•t'].apply(normalize_active)
            df['_conc'] = df['N·ªìng ƒë·ªô/h√†m l∆∞·ª£ng'].apply(normalize_conc)
            df['_grp'] = df['Nh√≥m thu·ªëc'].apply(normalize_group)
            # merge
            comp = file2.copy()
            comp['__act'] = comp['T√™n ho·∫°t ch·∫•t'].apply(normalize_active)
            comp['__conc'] = comp['N·ªìng ƒë·ªô/H√†m l∆∞·ª£ng'].apply(normalize_conc)
            comp['__grp'] = comp['Nh√≥m thu·ªëc'].apply(normalize_group)
            merged = df.merge(comp, left_on=['_act','_conc','_grp'],
                             right_on=['__act','__conc','__grp'], how='left', suffixes=('','_cmp'))
            # map hosp info
            hospmap = file3[['T√™n s·∫£n ph·∫©m','ƒê·ªãa b√†n','T√™n Kh√°ch h√†ng ph·ª• tr√°ch tri·ªÉn khai']]
            merged = merged.merge(hospmap, on='T√™n s·∫£n ph·∫©m', how='left')
            # calculate SL total per treatment group
            tm = {normalize_active(a):g for a,g in zip(file4['Ho·∫°t ch·∫•t'],file4['Nh√≥m ƒëi·ªÅu tr·ªã'])}
            totals = {}
            for _,r in df.iterrows():
                g = tm.get(r['_act'],None)
                q = pd.to_numeric(r.get('S·ªë l∆∞·ª£ng',0),errors='coerce') or 0
                if g: totals[g]=totals.get(g,0)+q
            # add ratio
            ratios=[]
            for _,r in merged.iterrows():
                g = tm.get(r['_act'],None)
                q = pd.to_numeric(r.get('S·ªë l∆∞·ª£ng',0),errors='coerce') or 0
                if g and totals.get(g,0)>0:
                    ratios.append(f"{q/totals[g]:.2%}")
                else:
                    ratios.append(None)
            merged['T·ª∑ tr·ªçng nh√≥m th·∫ßu'] = ratios
            # UI show only matched
            df_matched = merged[~merged['T√™n s·∫£n ph·∫©m_cmp'].isna()]
            st.success(f'‚úÖ ƒê√£ l·ªçc {len(df_matched)} d√≤ng ph√π h·ª£p.')
            st.dataframe(df_matched, height=400)
            # download full
            buf=BytesIO()
            writer=pd.ExcelWriter(buf,engine='xlsxwriter')
            merged.to_excel(writer,index=False,sheet_name='Full')
            writer.save()
            st.download_button('‚¨áÔ∏è Xu·∫•t full k·∫øt qu·∫£',buf.getvalue(), 'ketqua.xlsx')
            st.session_state['filtered']=merged
            st.session_state['matched']=df_matched
            st.session_state['hospital']=hosp

# ... ti·∫øp c√°c ch·ª©c nƒÉng 2,3,4,5 t∆∞∆°ng t·ª± v·ªõi UI v√† placeholder logic ...

else:
    st.info('Ch·ª©c nƒÉng ƒëang ƒë∆∞·ª£c ph√°t tri·ªÉn.')
