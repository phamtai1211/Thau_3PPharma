import streamlit as st
import pandas as pd
import numpy as np
import re
import unicodedata
import requests
from io import BytesIO
import plotly.express as px

# ‚Äî‚Äî Helper Functions ‚Äî‚Äî
def remove_accents(s: str) -> str:
    nkfd = unicodedata.normalize("NFKD", str(s))
    return "".join(c for c in nkfd if not unicodedata.combining(c))

def norm(s: str) -> str:
    return re.sub(r"\s+", " ", remove_accents(s).lower().strip())

def find_header_row(df: pd.DataFrame) -> int | None:
    keys = ["ho·∫°t ch·∫•t","t√™n th√†nh ph·∫ßn","s·ªë l∆∞·ª£ng","n·ªìng ƒë·ªô","h√†m l∆∞·ª£ng","nh√≥m thu·ªëc"]
    for i in range(min(20, len(df))):
        text = " ".join(df.iloc[i].fillna("").astype(str).tolist()).lower()
        if any(k in text for k in ["ho·∫°t ch·∫•t"]) and any(k in text for k in ["s·ªë l∆∞·ª£ng","n·ªìng ƒë·ªô"]):
            return i
    return None

@st.cache_data
def load_defaults():
    urls = {
        "file2": "https://raw.githubusercontent.com/phamtai1211/Thau_3PPharma/main/file2.xlsx",
        "file3": "https://raw.githubusercontent.com/phamtai1211/Thau_3PPharma/main/file3.xlsx",
        "file4": "https://raw.githubusercontent.com/phamtai1211/Thau_3PPharma/main/nhom_dieu_tri.xlsx"
    }
    f2 = pd.read_excel(BytesIO(requests.get(urls["file2"]).content))
    f3 = pd.read_excel(BytesIO(requests.get(urls["file3"]).content))
    f4 = pd.read_excel(BytesIO(requests.get(urls["file4"]).content))
    return f2, f3, f4

# ‚Äî‚Äî Load Data ‚Äî‚Äî
file2, file3, file4 = load_defaults()

# Filter inactive areas
file3["ƒê·ªãa b√†n"] = file3["ƒê·ªãa b√†n"].fillna("")
file3 = file3[~file3["ƒê·ªãa b√†n"].str.contains("t·∫°m ng∆∞ng tri·ªÉn khai|ko c√≥ ƒë·ªãa b√†n", case=False)]
st.session_state["file3"] = file3

# Sidebar
st.sidebar.title("Ch·ª©c nƒÉng")
option = st.sidebar.radio("", [
    "L·ªçc Danh M·ª•c Th·∫ßu",
    "Ph√¢n T√≠ch Danh M·ª•c Th·∫ßu",
    "Ph√¢n T√≠ch Danh M·ª•c Tr√∫ng Th·∫ßu",
    "ƒê·ªÅ Xu·∫•t H∆∞·ªõng Tri·ªÉn Khai",
])
conc_keys = ["n·ªìng ƒë·ªô","h√†m l∆∞·ª£ng"]

# ‚Äî‚Äî 1. L·ªçc Danh M·ª•c Th·∫ßu ‚Äî‚Äî
if option == "L·ªçc Danh M·ª•c Th·∫ßu":
    st.header("üìÇ L·ªçc Danh M·ª•c Th·∫ßu")
    df3 = st.session_state["file3"].copy()
    R = st.selectbox("Mi·ªÅn", ["(T·∫•t c·∫£)"] + sorted(df3["Mi·ªÅn"].dropna().unique()))
    if R != "(T·∫•t c·∫£)": df3 = df3[df3["Mi·ªÅn"] == R]
    A = st.selectbox("V√πng", ["(T·∫•t c·∫£)"] + sorted(df3["V√πng"].dropna().unique()))
    if A != "(T·∫•t c·∫£)": df3 = df3[df3["V√πng"] == A]
    P = st.selectbox("T·ªânh", ["(T·∫•t c·∫£)"] + sorted(df3["T·ªânh"].dropna().unique()))
    if P != "(T·∫•t c·∫£)": df3 = df3[df3["T·ªânh"] == P]
    H = st.selectbox("BV/SYT", sorted(df3["B·ªánh vi·ªán/SYT"].dropna().unique()))

    up = st.file_uploader("File M·ªùi Th·∫ßu (.xlsx)", type="xlsx")
    if not up:
        st.info("T·∫£i l√™n file m·ªùi th·∫ßu")
        st.stop()

    xls = pd.ExcelFile(up)
    sheet = max(xls.sheet_names, key=lambda n: xls.parse(n, nrows=1, header=None).shape[1])
    raw = pd.read_excel(up, sheet, header=None)
    hdr = find_header_row(raw)
    if hdr is None:
        st.error("Kh√¥ng t√¨m th·∫•y header trong 20 d√≤ng ƒë·∫ßu.")
        st.stop()

    cols = raw.iloc[hdr].tolist()
    df = raw.iloc[hdr+1:].reset_index(drop=True)
    df.columns = cols
    df = df.dropna(how="all").reset_index(drop=True)

    # Dynamic column detection
    act_col = next((c for c in df.columns if "ho·∫°t ch·∫•t" in norm(c) or "t√™n th√†nh ph·∫ßn" in norm(c)), None)
    conc_col = next((c for c in df.columns if any(k in norm(c) for k in conc_keys)), None)
    grp_col = next((c for c in df.columns if "nh√≥m" in norm(c)), "Nh√≥m thu·ªëc")
    if not act_col or not conc_col:
        st.error("Kh√¥ng t√¨m th·∫•y c·ªôt ho·∫°t ch·∫•t ho·∫∑c h√†m l∆∞·ª£ng.")
        st.stop()

    df["_act"] = df[act_col].apply(norm)
    df["_conc"] = df[conc_col].apply(norm)
    df["_grp"] = df[grp_col].astype(str).apply(lambda x: re.sub(r"\D","",x))

    cmp = file2.copy()
    cmp_act = next((c for c in cmp.columns if "ho·∫°t ch·∫•t" in norm(c)), "T√™n ho·∫°t ch·∫•t")
    cmp_conc = next((c for c in cmp.columns if any(k in norm(c) for k in conc_keys)), "N·ªìng ƒë·ªô/H√†m l∆∞·ª£ng")
    cmp_grp = next((c for c in cmp.columns if "nh√≥m" in norm(c)), "Nh√≥m thu·ªëc")
    cmp["_act"] = cmp[cmp_act].apply(norm)
    cmp["_conc"] = cmp[cmp_conc].apply(norm)
    cmp["_grp"] = cmp[cmp_grp].astype(str).apply(lambda x: re.sub(r"\D","",x))

    merged = pd.merge(df, cmp, on=["_act","_conc","_grp"], how="left", suffixes=("","_cmp"))
    info3 = df3[df3["B·ªánh vi·ªán/SYT"]==H][["T√™n s·∫£n ph·∫©m","ƒê·ªãa b√†n","T√™n Kh√°ch h√†ng ph·ª• tr√°ch tri·ªÉn khai"]].drop_duplicates()
    merged = pd.merge(merged, info3, on="T√™n s·∫£n ph·∫©m", how="left")

    merged["S·ªë l∆∞·ª£ng"] = pd.to_numeric(merged.get("S·ªë l∆∞·ª£ng",0), errors="coerce").fillna(0)
    valid = merged["_grp"].isin([str(i) for i in range(1,6)])
    grp_sum = merged[valid].groupby("Nh√≥m thu·ªëc")["S·ªë l∆∞·ª£ng"].transform("sum")
    merged["T·ª∑ tr·ªçng nh√≥m th·∫ßu"] = 0
    merged.loc[valid,"T·ª∑ tr·ªçng nh√≥m th·∫ßu"] = (merged.loc[valid,"S·ªë l∆∞·ª£ng"]/grp_sum).apply(lambda x: f"{x:.2%}")

    st.success(f"‚úÖ ƒê√£ l·ªçc xong {len(merged)} d√≤ng.")
    disp = merged.drop_duplicates(subset=["_act","_conc","_grp"])
    st.dataframe(disp[[act_col,conc_col,grp_col,"T√™n s·∫£n ph·∫©m","ƒê·ªãa b√†n","T√™n Kh√°ch h√†ng ph·ª• tr√°ch tri·ªÉn khai","T·ª∑ tr·ªçng nh√≥m th·∫ßu"]], height=500)

    buf = BytesIO()
    merged.to_excel(buf, index=False, sheet_name="K·∫øtQu·∫£")
    st.download_button("‚¨áÔ∏è T·∫£i full", buf.getvalue(), "KetQuaLoc.xlsx")
    st.session_state.update({"merged":merged,"df_body":df})

# ‚Äî‚Äî 2. Ph√¢n T√≠ch Danh M·ª•c Th·∫ßu ‚Äî‚Äî
elif option == "Ph√¢n T√≠ch Danh M·ª•c Th·∫ßu":
    st.header("üìä Ph√¢n T√≠ch Danh M·ª•c Th·∫ßu")
    if "df_body" not in st.session_state:
        st.info("Ch·∫°y L·ªçc Danh M·ª•c Th·∫ßu tr∆∞·ªõc.")
        st.stop()

    dfA = st.session_state["df_body"].copy()
    dfA["S·ªë l∆∞·ª£ng"] = pd.to_numeric(dfA.get("S·ªë l∆∞·ª£ng",0), errors="coerce").fillna(0)
    dfA["Gi√° k·∫ø ho·∫°ch"] = pd.to_numeric(dfA.get("Gi√° k·∫ø ho·∫°ch",0), errors="coerce").fillna(0)
    dfA["Tr·ªã gi√°"] = dfA["S·ªë l∆∞·ª£ng"]*dfA["Gi√° k·∫ø ho·∫°ch"]

    term = st.text_input("üîç Tra c·ª©u ho·∫°t ch·∫•t (nh·∫≠p m·ªôt ph·∫ßn)")
    if term:
        dfA = dfA[dfA[act_col].str.contains(term, case=False, na=False)]

    def plot(df, x, y, title):
        fig = px.bar(df, x=x, y=y, title=title)
        fig.update_traces(texttemplate="%{y:,.0f}", textposition="outside")
        st.plotly_chart(fig, use_container_width=True)

    # Nh√≥m thu·ªëc t·ªïng
    plot(dfA.groupby(grp_col)["Tr·ªã gi√°"].sum().reset_index(), grp_col, "Tr·ªã gi√°", "Tr·ªã gi√° theo Nh√≥m thu·ªëc")
    # ƒê∆∞·ªùng d√πng
    dfA["ƒê∆∞·ªùng"] = dfA["ƒê∆∞·ªùng d√πng"].apply(lambda s: "Ti√™m" if "ti√™m" in str(s).lower() else ("U·ªëng" if "u·ªëng" in str(s).lower() else "Kh√°c"))
    plot(dfA.groupby("ƒê∆∞·ªùng")["Tr·ªã gi√°"].sum().reset_index(), "ƒê∆∞·ªùng","Tr·ªã gi√°","Tr·ªã gi√° theo ƒê∆∞·ªùng d√πng")

    # Top10 HC ph√¢n theo Ti√™m/U·ªëng v√† SL/Tr·ªã gi√°
    for route in ["Ti√™m","U·ªëng"]:
        sub = dfA[dfA["ƒê∆∞·ªùng"]==route]
        plot(sub.groupby(act_col)["Tr·ªã gi√°"].sum().reset_index().sort_values("Tr·ªã gi√°",ascending=False).head(10), act_col, "Tr·ªã gi√°", f"Top10 {route} theo Tr·ªã gi√°")
        plot(sub.groupby(act_col)["S·ªë l∆∞·ª£ng"].sum().reset_index().sort_values("S·ªë l∆∞·ª£ng",ascending=False).head(10), act_col, "S·ªë l∆∞·ª£ng", f"Top10 {route} theo S·ªë l∆∞·ª£ng")

    # Nh√≥m ƒëi·ªÅu tr·ªã
    tm = {norm(a):g for a,g in zip(file4["Ho·∫°t ch·∫•t"],file4["Nh√≥m ƒëi·ªÅu tr·ªã"])}
    dfA["Nh√≥m ƒëi·ªÅu tr·ªã"] = dfA[act_col].apply(lambda x: tm.get(norm(x),"Kh√°c"))
    t2 = dfA.groupby("Nh√≥m ƒëi·ªÅu tr·ªã")[ ["S·ªë l∆∞·ª£ng","Tr·ªã gi√°"] ].sum().reset_index()
    plot(t2.sort_values("S·ªë l∆∞·ª£ng",False),"Nh√≥m ƒëi·ªÅu tr·ªã","S·ªë l∆∞·ª£ng","SL theo Nh√≥m ƒëi·ªÅu tr·ªã")
    sel = st.selectbox("Ch·ªçn Nh√≥m ƒëi·ªÅu tr·ªã xem Top10 HC (Tr·ªã gi√°)", t2["Nh√≥m ƒëi·ªÅu tr·ªã"])
    if sel:
        plot(dfA[dfA["Nh√≥m ƒëi·ªÅu tr·ªã"]==sel].groupby(act_col)["Tr·ªã gi√°"].sum().reset_index().sort_values("Tr·ªã gi√°",False).head(10),act_col,"Tr·ªã gi√°",f"Top10 HC theo Tr·ªã gi√° - {sel}")

# ‚Äî‚Äî 3. Ph√¢n T√≠ch Danh M·ª•c Tr√∫ng Th·∫ßu ‚Äî‚Äî
elif option == "Ph√¢n T√≠ch Danh M·ª•c Tr√∫ng Th·∫ßu":
    st.header("üèÜ Ph√¢n T√≠ch Danh M·ª•c Tr√∫ng Th·∫ßu")
    win = st.file_uploader("File Tr√∫ng Th·∫ßu (.xlsx)", type="xlsx")
    if not win:
        st.info("T·∫£i l√™n file tr√∫ng th·∫ßu")
        st.stop()
    xlsw = pd.ExcelFile(win)
    sw = max(xlsw.sheet_names, key=lambda n: xlsw.parse(n,nrows=1,header=None).shape[1])
    raww = pd.read_excel(win,sw,header=None)
    hw = find_header_row(raww)
    if hw is None:
        st.error("Kh√¥ng t√¨m header tr√∫ng th·∫ßu.")
        st.stop()
    hdrw = raww.iloc[hw].tolist()
    dfw = raww.iloc[hw+1:].reset_index(drop=True)
    dfw.columns = hdrw
    dfw = dfw.dropna(how="all").reset_index(drop=True)
    dfw["S·ªë l∆∞·ª£ng"] = pd.to_numeric(dfw.get("S·ªë l∆∞·ª£ng",0),errors="coerce").fillna(0)
    pcol = next((c for c in dfw.columns if "gi√° tr√∫ng" in norm(c)), "Gi√° k·∫ø ho·∫°ch")
    dfw[pcol] = pd.to_numeric(dfw.get(pcol,0),errors="coerce").fillna(0)
    dfw["Tr·ªã gi√°"] = dfw["S·ªë l∆∞·ª£ng"]*dfw[pcol]
    wv = dfw.groupby("Nh√† th·∫ßu tr√∫ng")["Tr·ªã gi√°"].sum().reset_index().sort_values("Tr·ªã gi√°",False).head(20)
    f1=px.bar(wv,x="Tr·ªã gi√°",y="Nh√† th·∫ßu tr√∫ng",orientation="h",title="Top20 Nh√† th·∫ßu tr√∫ng")
    f1.update_traces(texttemplate="%{x:,.0f}",textposition="outside")
    st.plotly_chart(f1,use_container_width=True)
    dfw["Nh√≥m ƒëi·ªÅu tr·ªã"] = dfw[act_col].apply(lambda x: tm.get(norm(x),"Kh√°c"))
    tw = dfw.groupby("Nh√≥m ƒëi·ªÅu tr·ªã")["Tr·ªã gi√°"].sum().reset_index()
    f2=px.pie(tw,names="Nh√≥m ƒëi·ªÅu tr·ªã",values="Tr·ªã gi√°",title="C∆° c·∫•u tr√∫ng th·∫ßu")
    st.plotly_chart(f2,use_container_width=True)

# ‚Äî‚Äî 4. ƒê·ªÅ Xu·∫•t H∆∞·ªõng Tri·ªÉn Khai ‚Äî‚Äî
elif option == "ƒê·ªÅ Xu·∫•t H∆∞·ªõng Tri·ªÉn Khai":
    st.header("üí° ƒê·ªÅ Xu·∫•t H∆∞·ªõng Tri·ªÉn Khai")
    if "merged" not in st.session_state:
        st.info("Ch·∫°y L·ªçc tr∆∞·ªõc.")
        st.stop()
    mdf = st.session_state["merged"].copy()
    done = mdf.groupby(["_act","_conc","_grp"])["S·ªë l∆∞·ª£ng"].sum().reset_index().rename(columns={"S·ªë l∆∞·ª£ng":"SL_ƒê√£ l√†m"})
    req = file3.copy()
    act3 = next((c for c in req.columns if "ho·∫°t ch·∫•t" in norm(c)), None)
    conc3 = next((c for c in req.columns if any(k in norm(c) for k in conc_keys)), None)
    grp3  = next((c for c in req.columns if "nh√≥m" in norm(c)), None)
    if not act3 or not conc3 or not grp3:
        st.error("Kh√¥ng t√¨m ƒë·ªß c·ªôt trong file3 ƒë·ªÉ ƒë·ªÅ xu·∫•t.")
        st.stop()
    req["_act"] = req[act3].apply(norm)
    req["_conc"] = req[conc3].apply(norm)
    req["_grp"] = req[grp3].astype(str).apply(lambda x: re.sub(r"\D","",x))
    req = req.groupby(["_act","_conc","_grp"])["S·ªë l∆∞·ª£ng"].sum().reset_index().rename(columns={"S·ªë l∆∞·ª£ng":"SL_Y√™u c·∫ßu"})
    sug = pd.merge(req, done, on=["_act","_conc","_grp"], how="left").fillna(0)
    sug["ƒê·ªÅ xu·∫•t"] = (sug["SL_Y√™u c·∫ßu"]-sug["SL_ƒê√£ l√†m"]).clip(lower=0).astype(int)
    kh = file3.copy()
    kh["_act"] = kh[act3].apply(norm)
    kh["_conc"] = kh[conc3].apply(norm)
    kh["_grp"] = kh[grp3].astype(str).apply(lambda x: re.sub(r"\D","",x))
    kh = kh.groupby(["_act","_conc","_grp"])["T√™n Kh√°ch h√†ng ph·ª• tr√°ch tri·ªÉn khai"].first().reset_index()
    sug = pd.merge(sug, kh, on=["_act","_conc","_grp"], how="left")
    st.dataframe(sug.sort_values("ƒê·ªÅ xu·∫•t",False).reset_index(drop=True))
