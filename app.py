import streamlit as st
import pandas as pd
import numpy as np
import re
import unicodedata
import requests
from io import BytesIO
import plotly.express as px

# ‚Äî‚Äî‚Äî Helper functions ‚Äî‚Äî‚Äî
def remove_accents(s: str) -> str:
    nkfd = unicodedata.normalize("NFKD", str(s))
    return "".join(c for c in nkfd if not unicodedata.combining(c))

def norm(s: str) -> str:
    return re.sub(r"\s+", " ", remove_accents(s).lower().strip())

def find_header_row(df: pd.DataFrame) -> int | None:
    keys = ["ho·∫°t ch·∫•t","t√™n th√†nh ph·∫ßn","s·ªë l∆∞·ª£ng","n·ªìng ƒë·ªô","h√†m l∆∞·ª£ng","nh√≥m thu·ªëc"]
    for i in range(min(20, len(df))):
        found = set()
        for cell in df.iloc[i].fillna(""):
            txt = str(cell).lower()
            for k in keys:
                if k in txt:
                    found.add(k)
        if len(found) >= 2:
            return i
    return None

@st.cache_data
def load_defaults():
    urls = {
        "file2":"https://raw.githubusercontent.com/phamtai1211/Thau_3PPharma/main/file2.xlsx",
        "file3":"https://raw.githubusercontent.com/phamtai1211/Thau_3PPharma/main/file3.xlsx",
        "file4":"https://raw.githubusercontent.com/phamtai1211/Thau_3PPharma/main/nhom_dieu_tri.xlsx"
    }
    f2 = pd.read_excel(BytesIO(requests.get(urls["file2"]).content))
    f3 = pd.read_excel(BytesIO(requests.get(urls["file3"]).content))
    f4 = pd.read_excel(BytesIO(requests.get(urls["file4"]).content))
    return f2, f3, f4

# ‚Äî‚Äî‚Äî Load ‚Äî‚Äî‚Äî
file2, file3, file4 = load_defaults()

# filter file3
file3["ƒê·ªãa b√†n"] = file3["ƒê·ªãa b√†n"].fillna("")
file3 = file3[~file3["ƒê·ªãa b√†n"].str.contains("t·∫°m ng∆∞ng tri·ªÉn khai|ko c√≥ ƒë·ªãa b√†n", case=False)]
st.session_state["file3"] = file3

# sidebar
st.sidebar.title("Ch·ª©c nƒÉng")
option = st.sidebar.radio("", [
    "L·ªçc Danh M·ª•c Th·∫ßu",
    "Ph√¢n T√≠ch Danh M·ª•c Th·∫ßu",
    "Ph√¢n T√≠ch Danh M·ª•c Tr√∫ng Th·∫ßu",
    "ƒê·ªÅ Xu·∫•t H∆∞·ªõng Tri·ªÉn Khai",
])

# precalc normalized keywords for conc detection
conc_keys = [norm("n·ªìng ƒë·ªô"), norm("h√†m l∆∞·ª£ng")]

# ‚Äî‚Äî‚Äî 1. L·ªçc Danh M·ª•c Th·∫ßu ‚Äî‚Äî‚Äî
if option == "L·ªçc Danh M·ª•c Th·∫ßu":
    st.header("üìÇ L·ªçc Danh M·ª•c Th·∫ßu")

    # ch·ªçn mi·ªÅn/v√πng/t·ªânh/bv
    df3 = st.session_state["file3"].copy()
    R = st.selectbox("Mi·ªÅn", ["(T·∫•t c·∫£)"] + sorted(df3["Mi·ªÅn"].dropna().unique()))
    if R!="(T·∫•t c·∫£)": df3 = df3[df3["Mi·ªÅn"]==R]
    A = st.selectbox("V√πng", ["(T·∫•t c·∫£)"] + sorted(df3["V√πng"].dropna().unique()))
    if A!="(T·∫•t c·∫£)"]: df3 = df3[df3["V√πng"]==A]
    P = st.selectbox("T·ªânh", ["(T·∫•t c·∫£)"] + sorted(df3["T·ªânh"].dropna().unique()))
    if P!="(T·∫•t c·∫£)"]: df3 = df3[df3["T·ªânh"]==P]
    H = st.selectbox("BV/SYT", sorted(df3["B·ªánh vi·ªán/SYT"].dropna().unique()))

    up = st.file_uploader("File M·ªùi Th·∫ßu (.xlsx)", type="xlsx")
    if not up:
        st.info("T·∫£i l√™n file m·ªùi th·∫ßu")
        st.stop()

    xls = pd.ExcelFile(up)
    sheet = max(xls.sheet_names, key=lambda n: xls.parse(n,nrows=1,header=None).shape[1])
    raw = pd.read_excel(up, sheet_name=sheet, header=None)

    hdr = find_header_row(raw)
    if hdr is None:
        st.error("Kh√¥ng t√¨m th·∫•y header trong 20 d√≤ng ƒë·∫ßu.")
        st.stop()

    cols = raw.iloc[hdr].tolist()
    df = raw.iloc[hdr+1:].reset_index(drop=True)
    df.columns = cols
    df = df.dropna(how="all").reset_index(drop=True)

    # --- T·ª∞ ƒê·ªòNG T√åM C·ªòT H√ÄM L∆Ø·ª¢NG ---
    conc_col = None
    for c in df.columns:
        cc = norm(c)
        if any(k in cc for k in conc_keys):
            conc_col = c
            break
    if conc_col is None:
        st.error("Kh√¥ng t√¨m th·∫•y c·ªôt n·ªìng ƒë·ªô/h√†m l∆∞·ª£ng.")
        st.stop()

    # chu·∫©n h√≥a keys
    df["_act"]  = df["T√™n ho·∫°t ch·∫•t"].apply(norm)
    df["_conc"] = df[conc_col].apply(norm)
    df["_grp"]  = df["Nh√≥m thu·ªëc"].astype(str).apply(lambda x: re.sub(r"\D","",x))

    # company list
    cmp = file2.copy()
    cmp["_act"]  = cmp["T√™n ho·∫°t ch·∫•t"].apply(norm)
    cmp["_conc"] = cmp["N·ªìng ƒë·ªô/H√†m l∆∞·ª£ng"].apply(norm)
    cmp["_grp"]  = cmp["Nh√≥m thu·ªëc"].astype(str).apply(lambda x: re.sub(r"\D","",x))

    merged = pd.merge(df, cmp, on=["_act","_conc","_grp"], how="left", suffixes=("","_cmp"))

    info3 = df3[df3["B·ªánh vi·ªán/SYT"]==H][
        ["T√™n s·∫£n ph·∫©m","ƒê·ªãa b√†n","T√™n Kh√°ch h√†ng ph·ª• tr√°ch tri·ªÉn khai"]
    ].drop_duplicates()
    merged = pd.merge(merged, info3, on="T√™n s·∫£n ph·∫©m", how="left")

    # t·ª∑ tr·ªçng nh√≥m N1‚ÄìN5
    merged["S·ªë l∆∞·ª£ng"] = pd.to_numeric(merged.get("S·ªë l∆∞·ª£ng",0),errors="coerce").fillna(0)
    grp_ok = merged["_grp"].isin([str(i) for i in range(1,6)])
    tot = merged[grp_ok].groupby("Nh√≥m thu·ªëc")["S·ªë l∆∞·ª£ng"].transform("sum")
    merged["T·ª∑ tr·ªçng nh√≥m th·∫ßu"] = 0
    merged.loc[grp_ok,"T·ª∑ tr·ªçng nh√≥m th·∫ßu"] = (
        merged.loc[grp_ok,"S·ªë l∆∞·ª£ng"] / tot
    ).fillna(0).apply(lambda x: f"{x:.2%}")

    st.session_state["merged"] = merged
    st.session_state["df_body"] = df

    st.success(f"‚úÖ ƒê√£ l·ªçc xong {len(merged)} d√≤ng.")
    disp = merged.drop_duplicates(subset=["_act","_conc","_grp"])
    disp = disp[disp["T√™n s·∫£n ph·∫©m"].notna()]
    st.dataframe(
        disp[[
            "T√™n ho·∫°t ch·∫•t", conc_col, "Nh√≥m thu·ªëc",
            "T√™n s·∫£n ph·∫©m","ƒê·ªãa b√†n","T√™n Kh√°ch h√†ng ph·ª• tr√°ch tri·ªÉn khai",
            "T·ª∑ tr·ªçng nh√≥m th·∫ßu"
        ]],
        height=500
    )

    buf = BytesIO()
    merged.to_excel(buf,index=False,sheet_name="KQ")
    st.download_button("‚¨áÔ∏è T·∫£i full", buf.getvalue(), "KQ.xlsx")

# ‚Äî‚Äî‚Äî 2. Ph√¢n T√≠ch Danh M·ª•c Th·∫ßu ‚Äî‚Äî‚Äî
elif option == "Ph√¢n T√≠ch Danh M·ª•c Th·∫ßu":
    st.header("üìä Ph√¢n T√≠ch Danh M·ª•c Th·∫ßu")
    if "df_body" not in st.session_state:
        st.info("Ch·∫°y L·ªçc tr∆∞·ªõc.")
        st.stop()

    dfA = st.session_state["df_body"].copy()
    dfA["S·ªë l∆∞·ª£ng"] = pd.to_numeric(dfA["S·ªë l∆∞·ª£ng"],errors="coerce").fillna(0)
    dfA["Gi√° k·∫ø ho·∫°ch"] = pd.to_numeric(dfA.get("Gi√° k·∫ø ho·∫°ch",0),errors="coerce").fillna(0)
    dfA["Tr·ªã gi√°"] = dfA["S·ªë l∆∞·ª£ng"]*dfA["Gi√° k·∫ø ho·∫°ch"]

    term = st.text_input("üîç Tra c·ª©u ho·∫°t ch·∫•t")
    if term:
        dfA = dfA[dfA["T√™n ho·∫°t ch·∫•t"].str.contains(term, case=False, na=False)]

    pd.options.display.float_format = "{:,.0f}".format
    def plot_bar(df,x,y,t):
        fig=px.bar(df,x=x,y=y,title=t); fig.update_traces(texttemplate="%{y:,.0f}",textposition="outside")
        st.plotly_chart(fig,use_container_width=True)

    g1 = dfA.groupby("Nh√≥m thu·ªëc")["Tr·ªã gi√°"].sum().reset_index().sort_values("Tr·ªã gi√°",False)
    plot_bar(g1,"Nh√≥m thu·ªëc","Tr·ªã gi√°","Tr·ªã gi√° theo Nh√≥m thu·ªëc")
    dfA["ƒê∆∞·ªùng"] = dfA["ƒê∆∞·ªùng d√πng"].apply(lambda s: "Ti√™m" if "ti√™m" in str(s).lower() else ("U·ªëng" if "u·ªëng" in str(s).lower() else "Kh√°c"))
    g2 = dfA.groupby("ƒê∆∞·ªùng")["Tr·ªã gi√°"].sum().reset_index()
    plot_bar(g2,"ƒê∆∞·ªùng","Tr·ªã gi√°","Tr·ªã gi√° theo ƒê∆∞·ªùng d√πng")
    top_sl = dfA.groupby("T√™n ho·∫°t ch·∫•t")["S·ªë l∆∞·ª£ng"].sum().reset_index().sort_values("S·ªë l∆∞·ª£ng",False).head(10)
    top_v  = dfA.groupby("T√™n ho·∫°t ch·∫•t")["Tr·ªã gi√°"].sum().reset_index().sort_values("Tr·ªã gi√°",False).head(10)
    plot_bar(top_sl,"T√™n ho·∫°t ch·∫•t","S·ªë l∆∞·ª£ng","Top10 HC SL")
    plot_bar(top_v,"T√™n ho·∫°t ch·∫•t","Tr·ªã gi√°","Top10 HC Tr·ªã gi√°")

    tm = {norm(a):g for a,g in zip(file4["Ho·∫°t ch·∫•t"],file4["Nh√≥m ƒëi·ªÅu tr·ªã"])}
    dfA["Nh√≥m ƒëi·ªÅu tr·ªã"] = dfA["T√™n ho·∫°t ch·∫•t"].apply(lambda x: tm.get(norm(x),"Kh√°c"))
    t2 = dfA.groupby("Nh√≥m ƒëi·ªÅu tr·ªã")[["S·ªë l∆∞·ª£ng","Tr·ªã gi√°"]].sum().reset_index()
    plot_bar(t2.sort_values("S·ªë l∆∞·ª£ng",False),"Nh√≥m ƒëi·ªÅu tr·ªã","S·ªë l∆∞·ª£ng","SL theo ƒêi·ªÅu tr·ªã")
    sel = st.selectbox("Ch·ªçn nh√≥m ƒëi·ªÅu tr·ªã xem Top10 HC (Tr·ªã gi√°)",t2["Nh√≥m ƒëi·ªÅu tr·ªã"])
    if sel:
        t3 = dfA[dfA["Nh√≥m ƒëi·ªÅu tr·ªã"]==sel].groupby("T√™n ho·∫°t ch·∫•t")["Tr·ªã gi√°"].sum().reset_index().sort_values("Tr·ªã gi√°",False).head(10)
        plot_bar(t3,"T√™n ho·∫°t ch·∫•t","Tr·ªã gi√°",f"Top10 HC Tr·ªã gi√° - {sel}")

# ‚Äî‚Äî‚Äî 3. Ph√¢n T√≠ch Danh M·ª•c Tr√∫ng Th·∫ßu ‚Äî‚Äî‚Äî
elif option == "Ph√¢n T√≠ch Danh M·ª•c Tr√∫ng Th·∫ßu":
    st.header("üèÜ Ph√¢n T√≠ch Danh M·ª•c Tr√∫ng Th·∫ßu")
    win = st.file_uploader("File Tr√∫ng Th·∫ßu (.xlsx)",type="xlsx")
    if not win:
        st.info("T·∫£i file tr√∫ng th·∫ßu")
        st.stop()

    xlsw=pd.ExcelFile(win)
    sw=max(xlsw.sheet_names,key=lambda n:xlsw.parse(n,nrows=1,header=None).shape[1])
    raww=pd.read_excel(win,sw,header=None)
    hw=find_header_row(raww)
    if hw is None:
        st.error("Kh√¥ng t√¨m header tr√∫ng th·∫ßu")
        st.stop()

    hdrw=raww.iloc[hw].tolist()
    dfw=raww.iloc[hw+1:].reset_index(drop=True); dfw.columns=hdrw; dfw=dfw.dropna(how="all").reset_index(drop=True)
    dfw["S·ªë l∆∞·ª£ng"]=pd.to_numeric(dfw.get("S·ªë l∆∞·ª£ng",0),errors="coerce").fillna(0)
    pcol=next((c for c in dfw.columns if "gi√° tr√∫ng" in norm(c)),"Gi√° k·∫ø ho·∫°ch")
    dfw[pcol]=pd.to_numeric(dfw.get(pcol,0),errors="coerce").fillna(0)
    dfw["Tr·ªã gi√°"]=dfw["S·ªë l∆∞·ª£ng"]*dfw[pcol]
    wv=dfw.groupby("Nh√† th·∫ßu tr√∫ng")["Tr·ªã gi√°"].sum().reset_index().sort_values("Tr·ªã gi√°",False).head(20)
    f1=px.bar(wv,x="Tr·ªã gi√°",y="Nh√† th·∫ßu tr√∫ng",orientation="h",title="Top20 Nh√† th·∫ßu")
    f1.update_traces(texttemplate="%{x:,.0f}",textposition="outside"); st.plotly_chart(f1,use_container_width=True)
    dfw["Nh√≥m ƒëi·ªÅu tr·ªã"]=dfw["T√™n ho·∫°t ch·∫•t"].apply(lambda x: tm.get(norm(x),"Kh√°c"))
    tw=dfw.groupby("Nh√≥m ƒëi·ªÅu tr·ªã")["Tr·ªã gi√°"].sum().reset_index()
    f2=px.pie(tw,names="Nh√≥m ƒëi·ªÅu tr·ªã",values="Tr·ªã gi√°",title="C∆° c·∫•u tr√∫ng th·∫ßu"); st.plotly_chart(f2,use_container_width=True)

# ‚Äî‚Äî‚Äî 4. ƒê·ªÅ Xu·∫•t H∆∞·ªõng Tri·ªÉn Khai ‚Äî‚Äî‚Äî
elif option == "ƒê·ªÅ Xu·∫•t H∆∞·ªõng Tri·ªÉn Khai":
    st.header("üí° ƒê·ªÅ Xu·∫•t H∆∞·ªõng Tri·ªÉn Khai")
    if "merged" not in st.session_state:
        st.info("Ch·∫°y L·ªçc tr∆∞·ªõc.")
        st.stop()

    mdf = st.session_state["merged"].copy()
    done = mdf.groupby(["_act","_conc","_grp"])["S·ªë l∆∞·ª£ng"].sum().reset_index().rename(columns={"S·ªë l∆∞·ª£ng":"SL_ƒê√£ l√†m"})
    # prepare req
    req = file3.copy()
    req["_act"]=req["T√™n ho·∫°t ch·∫•t"].apply(norm)
    conc3 = next((c for c in file3.columns if any(k in norm(c) for k in conc_keys)), None)
    if conc3 is None:
        st.error("Kh√¥ng t√¨m c·ªôt h√†m l∆∞·ª£ng file3")
        st.stop()
    req["_conc"]=req[conc3].apply(norm)
    req["_grp"]=req["Nh√≥m thu·ªëc"].astype(str).apply(lambda x:re.sub(r"\D","",x))
    req=req.groupby(["_act","_conc","_grp"])["S·ªë l∆∞·ª£ng"].sum().reset_index().rename(columns={"S·ªë l∆∞·ª£ng":"SL_Y√™u c·∫ßu"})
    sug=pd.merge(req,done,on=["_act","_conc","_grp"],how="left").fillna(0)
    sug["ƒê·ªÅ xu·∫•t"]=(sug["SL_Y√™u c·∫ßu"]-sug["SL_ƒê√£ l√†m"]).clip(lower=0).astype(int)
    kh=file3.copy()
    kh["_act"]=kh["T√™n ho·∫°t ch·∫•t"].apply(norm)
    kh["_conc"]=kh[conc3].apply(norm)
    kh["_grp"]=kh["Nh√≥m thu·ªëc"].astype(str).apply(lambda x:re.sub(r"\D","",x))
    kh=kh.groupby(["_act","_conc","_grp"])["T√™n Kh√°ch h√†ng ph·ª• tr√°ch tri·ªÉn khai"].first().reset_index()
    sug=pd.merge(sug,kh,on=["_act","_conc","_grp"],how="left")
    st.dataframe(sug,500)
