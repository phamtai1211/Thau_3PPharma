import streamlit as st
import pandas as pd
import numpy as np
import re
import requests
from io import BytesIO
import plotly.express as px

# --- H√†m d√≤ header ---
def find_header_index(df_raw):
    for i in range(10):
        row = " ".join(df_raw.iloc[i].fillna('').astype(str).tolist()).lower()
        if "t√™n ho·∫°t ch·∫•t" in row and "s·ªë l∆∞·ª£ng" in row:
            return i
    return None

# --- Chu·∫©n h√≥a ---
def normalize_active(name: str) -> str:
    return re.sub(r'\s+', ' ',
                  re.sub(r'\(.*?\)', '',
                         str(name))).strip().lower()

def normalize_concentration(conc: str) -> str:
    s = str(conc).lower().replace(',', '.').replace('dung t√≠ch', '')
    parts = [p.strip() for p in s.split(',') if re.search(r'\d', p)]
    if len(parts)>=2 and re.search(r'(mg|mcg|g|%)', parts[0]) and 'ml' in parts[-1] and '/' not in parts[0]:
        return parts[0].replace(' ','') + '/' + parts[-1].replace(' ','')
    return ''.join(p.replace(' ','') for p in parts)

def normalize_group(grp: str) -> str:
    return re.sub(r'\D', '', str(grp)).strip()

# --- Load d·ªØ li·ªáu c√¥ng ty & BV ---
@st.cache_data
def load_default_data():
    url2 = "https://raw.githubusercontent.com/phamtai1211/Thau_3PPharma/main/file2.xlsx"
    url3 = "https://raw.githubusercontent.com/phamtai1211/Thau_3PPharma/main/file3.xlsx"
    url4 = "https://raw.githubusercontent.com/phamtai1211/Thau_3PPharma/main/nhom_dieu_tri.xlsx"
    f2 = pd.read_excel(BytesIO(requests.get(url2).content))
    f3 = pd.read_excel(BytesIO(requests.get(url3).content))
    f4 = pd.read_excel(BytesIO(requests.get(url4).content))
    return f2, f3, f4

file2, file3, file4 = load_default_data()

# L·ªçc file3 (lo·∫°i b·ªè t·∫°m ng∆∞ng/ko c√≥ ƒë·ªãa b√†n)
file3 = file3[~file3["ƒê·ªãa b√†n"].astype(str)
              .str.contains("t·∫°m ng∆∞ng tri·ªÉn khai|ko c√≥ ƒë·ªãa b√†n", case=False, na=False)]

# Sidebar
st.sidebar.title("Ch·ª©c nƒÉng")
opt = st.sidebar.radio("", [
    "L·ªçc Danh M·ª•c Th·∫ßu",
    "Ph√¢n T√≠ch Danh M·ª•c Th·∫ßu",
    "Ph√¢n T√≠ch Danh M·ª•c Tr√∫ng Th·∫ßu",
    "ƒê·ªÅ Xu·∫•t H∆∞·ªõng Tri·ªÉn Khai",
])

# 1) L·ªçc Danh M·ª•c Th·∫ßu
if opt=="L·ªçc Danh M·ª•c Th·∫ßu":
    st.header("üìÇ L·ªçc Danh M·ª•c Th·∫ßu")
    # ch·ªçn BV
    regions = sorted(file3["Mi·ªÅn"].dropna().unique())
    r = st.selectbox("Mi·ªÅn", regions)
    sub = file3[file3["Mi·ªÅn"]==r]
    areas = sorted(sub["V√πng"].dropna().unique())
    a = st.selectbox("V√πng", ["(T·∫•t c·∫£)"]+areas)
    if a!="(T·∫•t c·∫£)": sub = sub[sub["V√πng"]==a]
    ps = sorted(sub["T·ªânh"].dropna().unique())
    p = st.selectbox("T·ªânh", ps)
    sub = sub[sub["T·ªânh"]==p]
    hosp = st.selectbox("BV/SYT", sorted(sub["B·ªánh vi·ªán/SYT"].dropna().unique()))

    up = st.file_uploader("File M·ªùi Th·∫ßu (.xlsx)", type="xlsx")
    if up and hosp:
        xls = pd.ExcelFile(up)
        # ch·ªçn sheet nhi·ªÅu c·ªôt nh·∫•t
        best, sheet = 0, None
        for nm in xls.sheet_names:
            try:
                c = xls.parse(nm, nrows=1, header=None).shape[1]
                if c>best:
                    best, sheet = c, nm
            except: pass

        df_raw = pd.read_excel(up, sheet_name=sheet, header=None)
        hi = find_header_index(df_raw)
        if hi is None:
            st.error("‚ùå Kh√¥ng t√¨m th·∫•y header trong 10 d√≤ng ƒë·∫ßu.")
            st.stop()

        # DataFrame g·ªëc (sau header), **kh√¥ng** dropna
        df_all = df_raw.iloc[hi+1:].reset_index(drop=True)
        df_all.columns = df_raw.iloc[hi].tolist()

        # Chu·∫©n h√≥a th√™m 3 c·ªôt ƒë·ªÉ merge
        df_all["active_norm"] = df_all["T√™n ho·∫°t ch·∫•t"].apply(normalize_active)
        df_all["conc_norm"]   = df_all["N·ªìng ƒë·ªô/h√†m l∆∞·ª£ng"].apply(normalize_concentration)
        df_all["grp_norm"]    = df_all["Nh√≥m thu·ªëc"].apply(normalize_group)

        # B·∫£ng tham chi·∫øu 1-1 t·ª´ file2
        df2 = file2.copy()
        df2["active_norm"] = df2["T√™n ho·∫°t ch·∫•t"].apply(normalize_active)
        df2["conc_norm"]   = df2["N·ªìng ƒë·ªô/H√†m l∆∞·ª£ng"].apply(normalize_concentration)
        df2["grp_norm"]    = df2["Nh√≥m thu·ªëc"].apply(normalize_group)
        comp_ref = df2[["active_norm","conc_norm","grp_norm","T√™n s·∫£n ph·∫©m"]].drop_duplicates(
            subset=["active_norm","conc_norm","grp_norm"]
        )

        # In s·ªë d√≤ng g·ªëc v√† merge
        n_in = df_all.shape[0]
        st.write(f"‚ùì D√≤ng sau header: **{n_in}**")
        m = pd.merge(
            df_all.reset_index(),
            comp_ref,
            on=["active_norm","conc_norm","grp_norm"],
            how="left"
        )
        res = (
            m.set_index("index")
             [ df_all.columns.tolist() + ["T√™n s·∫£n ph·∫©m"] ]
             .reset_index(drop=True)
        )
        n_out = res.shape[0]
        st.write(f"‚úÖ D√≤ng sau merge: **{n_out}**")

        # Th√™m ƒê·ªãa b√†n & Kh√°ch h√†ng ph·ª• tr√°ch t·ª´ file3
        hosp_df = file3[file3["B·ªánh vi·ªán/SYT"]==hosp][
            ["T√™n s·∫£n ph·∫©m","ƒê·ªãa b√†n","T√™n Kh√°ch h√†ng ph·ª• tr√°ch tri·ªÉn khai"]
        ]
        res = res.merge(hosp_df, on="T√™n s·∫£n ph·∫©m", how="left")

        # T√≠nh t·ª∑ tr·ªçng SL/DM T·ªïng theo NH√ìM ƒêI·ªÄU TR·ªä
        treat_map = {normalize_active(a):g for a,g in zip(
            file4["Ho·∫°t ch·∫•t"], file4["Nh√≥m ƒëi·ªÅu tr·ªã"]
        )}
        # t·ªïng theo nh√≥m tr√™n to√†n b·ªô m·ªùi th·∫ßu
        grp_tot = {}
        for _,r0 in df_all.iterrows():
            a0 = normalize_active(r0["T√™n ho·∫°t ch·∫•t"])
            g0 = treat_map.get(a0)
            q0 = pd.to_numeric(r0.get("S·ªë l∆∞·ª£ng",0), errors="coerce") or 0
            if g0: grp_tot[g0] = grp_tot.get(g0,0)+q0

        def calc_ratio(row):
            a0 = normalize_active(row["T√™n ho·∫°t ch·∫•t"])
            g0 = treat_map.get(a0)
            q0 = pd.to_numeric(row.get("S·ªë l∆∞·ª£ng",0), errors="coerce") or 0
            if not(g0 and grp_tot.get(g0)>0): return None
            return f"{q0/grp_tot[g0]:.2%}"

        res["T·ª∑ tr·ªçng SL/DM T·ªïng"] = res.apply(calc_ratio, axis=1)

        # Hi·ªÉn th·ªã v√† download
        st.dataframe(res, height=600)
        buf = BytesIO()
        with pd.ExcelWriter(buf, engine="xlsxwriter") as w:
            res.to_excel(w, index=False, sheet_name="KetQuaLoc")
        st.download_button("‚¨áÔ∏è T·∫£i v·ªÅ Excel", data=buf.getvalue(),
                           file_name="Ketqua_loc.xlsx")

        # L∆∞u session
        st.session_state["filtered_df"] = res
        st.session_state["hosp"] = hosp

# 2) Ph√¢n T√≠ch Danh M·ª•c Th·∫ßu
elif opt=="Ph√¢n T√≠ch Danh M·ª•c Th·∫ßu":
    st.header("üìä Ph√¢n T√≠ch Danh M·ª•c Th·∫ßu")
    if "filtered_df" not in st.session_state:
        st.info("Ch·∫°y 'L·ªçc Danh M·ª•c Th·∫ßu' tr∆∞·ªõc ƒë√£.")
        st.stop()
    df = st.session_state["filtered_df"].copy()
    df["S·ªë l∆∞·ª£ng"] = pd.to_numeric(df["S·ªë l∆∞·ª£ng"], errors="coerce").fillna(0)
    df["Gi√° k·∫ø ho·∫°ch"] = pd.to_numeric(df["Gi√° k·∫ø ho·∫°ch"], errors="coerce").fillna(0)
    df["Tr·ªã gi√°"] = df["S·ªë l∆∞·ª£ng"] * df["Gi√° k·∫ø ho·∫°ch"]

    # Nh√≥m th·∫ßu theo tr·ªã gi√°
    gv = df.groupby("Nh√≥m thu·ªëc")["Tr·ªã gi√°"].sum().reset_index().sort_values("Tr·ªã gi√°",False)
    fig = px.bar(gv, x="Nh√≥m thu·ªëc", y="Tr·ªã gi√°", text="Tr·ªã gi√°",
                 title="Tr·ªã gi√° theo Nh√≥m th·∫ßu")
    fig.update_traces(texttemplate="%{text:.2s}", textposition="outside")
    st.plotly_chart(fig, use_container_width=True)

    # ƒê∆∞·ªùng d√πng
    def cls(rt):
        r = str(rt).lower()
        if "ti√™m" in r: return "Ti√™m"
        if "u·ªëng" in r: return "U·ªëng"
        return "Kh√°c"
    df["ƒê∆∞·ªùng"] = df["ƒê∆∞·ªùng d√πng"].apply(cls)
    dv = df.groupby("ƒê∆∞·ªùng")["Tr·ªã gi√°"].sum().reset_index()
    st.plotly_chart(px.pie(dv,names="ƒê∆∞·ªùng",values="Tr·ªã gi√°",
                           title="C∆° c·∫•u ƒë∆∞·ªùng d√πng"))

    # Top10 HC theo Tr·ªã gi√°/S·ªë l∆∞·ª£ng, Ti√™m/U·ªëng
    for measure in ["S·ªë l∆∞·ª£ng","Tr·ªã gi√°"]:
        for route in ["Ti√™m","U·ªëng"]:
            sub = df[df["ƒê∆∞·ªùng"]==route]
            top = sub.groupby("T√™n ho·∫°t ch·∫•t")[measure].sum().reset_index() \
                     .sort_values(measure,False).head(10)
            st.subheader(f"Top10 HC {route} theo {measure}")
            st.plotly_chart(px.bar(top, x="T√™n ho·∫°t ch·∫•t", y=measure,
                                   text=measure).update_traces(
                                   texttemplate="%{text:.2s}", textposition="outside"
            ), use_container_width=True)

    # Nh√≥m ƒëi·ªÅu tr·ªã tr·ªã gi√° v√† SL
    tm = {normalize_active(a):g for a,g in zip(
        file4["Ho·∫°t ch·∫•t"], file4["Nh√≥m ƒëi·ªÅu tr·ªã"]
    )}
    df["Nh√≥m ƒëi·ªÅu tr·ªã"] = df["T√™n ho·∫°t ch·∫•t"].apply(
        lambda x: tm.get(normalize_active(x),"Kh√°c"))
    # Tr·ªã gi√°
    tv = df.groupby("Nh√≥m ƒëi·ªÅu tr·ªã")["Tr·ªã gi√°"].sum().reset_index().sort_values("Tr·ªã gi√°",False)
    st.plotly_chart(px.bar(tv, x="Nh√≥m ƒëi·ªÅu tr·ªã", y="Tr·ªã gi√°",
                           orientation="h", title="Tr·ªã gi√° theo Nh√≥m ƒëi·ªÅu tr·ªã"),
                   use_container_width=True)
    # S·ªë l∆∞·ª£ng
    sv = df.groupby("Nh√≥m ƒëi·ªÅu tr·ªã")["S·ªë l∆∞·ª£ng"].sum().reset_index().sort_values("S·ªë l∆∞·ª£ng",False)
    st.plotly_chart(px.bar(sv, x="Nh√≥m ƒëi·ªÅu tr·ªã", y="S·ªë l∆∞·ª£ng",
                           orientation="h", title="SL theo Nh√≥m ƒëi·ªÅu tr·ªã"),
                   use_container_width=True)

    # Top10 HC trong nh√≥m ƒëi·ªÅu tr·ªã
    sel = st.selectbox("Ch·ªçn Nh√≥m ƒëi·ªÅu tr·ªã", tv["Nh√≥m ƒëi·ªÅu tr·ªã"])
    if sel:
        tmp = df[df["Nh√≥m ƒëi·ªÅu tr·ªã"]==sel]
        topv = tmp.groupby("T√™n ho·∫°t ch·∫•t")["Tr·ªã gi√°"].sum().reset_index() \
                  .sort_values("Tr·ªã gi√°",False).head(10)
        st.plotly_chart(px.bar(topv, x="T√™n ho·∫°t ch·∫•t", y="Tr·ªã gi√°",
                               orientation="h",
                               title=f"Top10 HC - {sel} (Tr·ªã gi√°)"),
                       use_container_width=True)

# 3) Ph√¢n T√≠ch Danh M·ª•c Tr√∫ng Th·∫ßu
elif opt=="Ph√¢n T√≠ch Danh M·ª•c Tr√∫ng Th·∫ßu":
    st.header("üèÜ Ph√¢n T√≠ch Danh M·ª•c Tr√∫ng Th·∫ßu")
    win = st.file_uploader("File Tr√∫ng Th·∫ßu", type="xlsx")
    inv = st.file_uploader("ƒê·ªëi chi·∫øu M·ªùi Th·∫ßu (tu·ª≥ ch·ªçn)", type="xlsx")
    if not win:
        st.info("Upload file Tr√∫ng Th·∫ßu ƒë√£.")
        st.stop()
    # --- t∆∞∆°ng t·ª± nh∆∞ c≈©, d√≤ header, parse, t√≠nh Tr·ªã gi√°, v·∫Ω chart Nh√† th·∫ßu, Nh√≥m ƒëi·ªÅu tr·ªã ---
    # ... gi·ªØ nguy√™n logic ban ƒë·∫ßu c·ªßa anh ...

# 4) ƒê·ªÅ Xu·∫•t H∆∞·ªõng Tri·ªÉn Khai
elif opt=="ƒê·ªÅ Xu·∫•t H∆∞·ªõng Tri·ªÉn Khai":
    st.header("üí° ƒê·ªÅ Xu·∫•t H∆∞·ªõng Tri·ªÉn Khai")
    if "filtered_df" not in st.session_state:
        st.info("Ch·∫°y ph√¢n t√≠ch tr∆∞·ªõc ƒë√£.")
        st.stop()
    df = st.session_state["filtered_df"]
    hosp = st.session_state["hosp"]
    # --- logic ƒë·ªÅ xu·∫•t theo file3 v√† missing_items ---
    # ... gi·ªØ nguy√™n logic ban ƒë·∫ßu c·ªßa anh ...

