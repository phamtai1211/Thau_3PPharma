import streamlit as st
import pandas as pd
import numpy as np
import re
import unicodedata
import requests
from io import BytesIO
import plotly.express as px

# ‚Äî‚Äî‚Äî Helper Functions ‚Äî‚Äî‚Äî
def remove_accents(s: str) -> str:
    """Lo·∫°i b·ªè d·∫•u ti·∫øng Vi·ªát."""
    nkfd = unicodedata.normalize("NFKD", str(s))
    return "".join(c for c in nkfd if not unicodedata.combining(c))

def norm(s: str) -> str:
    """Normalize: no accents, lowercase, strip extra spaces."""
    s = remove_accents(s).lower().strip()
    return re.sub(r"\s+", " ", s)

def find_header_row(df: pd.DataFrame, keywords: list[str]) -> int | None:
    """
    T√¨m header row trong 10 d√≤ng ƒë·∫ßu.
    Ch·ªçn d√≤ng c√≥ >=2 t·ª´ kh√≥a xu·∫•t hi·ªán (ignore order).
    """
    for i in range(min(10, len(df))):
        row_text = " ".join(df.iloc[i].fillna("").astype(str)).lower()
        count = sum(1 for kw in keywords if kw in row_text)
        if count >= 2:
            return i
    return None

@st.cache_data
def load_default_data():
    """Load c√°c file m·∫∑c ƒë·ªãnh t·ª´ GitHub."""
    urls = {
        "file2":"https://raw.githubusercontent.com/phamtai1211/Thau_3PPharma/main/file2.xlsx",
        "file3":"https://raw.githubusercontent.com/phamtai1211/Thau_3PPharma/main/file3.xlsx",
        "file4":"https://raw.githubusercontent.com/phamtai1211/Thau_3PPharma/main/nhom_dieu_tri.xlsx"
    }
    file2 = pd.read_excel(BytesIO(requests.get(urls["file2"]).content))
    file3 = pd.read_excel(BytesIO(requests.get(urls["file3"]).content))
    file4 = pd.read_excel(BytesIO(requests.get(urls["file4"]).content))
    return file2, file3, file4

# ‚Äî‚Äî‚Äî Load data ‚Äî‚Äî‚Äî
file2, file3, file4 = load_default_data()

# L·ªçc file3: lo·∫°i b·ªè ‚Äút·∫°m ng∆∞ng tri·ªÉn khai‚Äù v√† ‚Äúko c√≥ ƒë·ªãa b√†n‚Äù
file3["ƒê·ªãa b√†n"] = file3["ƒê·ªãa b√†n"].fillna("")
file3 = file3[~file3["ƒê·ªãa b√†n"].str.contains("t·∫°m ng∆∞ng tri·ªÉn khai|ko c√≥ ƒë·ªãa b√†n", case=False)]
st.session_state["file3"] = file3

# ‚Äî‚Äî‚Äî Sidebar ‚Äî‚Äî‚Äî
st.sidebar.title("Ch·ª©c nƒÉng")
option = st.sidebar.radio("Ch·ªçn ch·ª©c nƒÉng", [
    "L·ªçc Danh M·ª•c Th·∫ßu",
    "Ph√¢n T√≠ch Danh M·ª•c Th·∫ßu",
    "Ph√¢n T√≠ch Danh M·ª•c Tr√∫ng Th·∫ßu",
    "ƒê·ªÅ Xu·∫•t H∆∞·ªõng Tri·ªÉn Khai"
])

# T·ª´ kh√≥a ƒë·ªÉ t√¨m header
HEADER_KEYS = ["t√™n ho·∫°t ch·∫•t", "n·ªìng ƒë·ªô", "h√†m l∆∞·ª£ng", "nh√≥m thu·ªëc", "s·ªë l∆∞·ª£ng"]

# ‚Äî‚Äî‚Äî 1. L·ªçc Danh M·ª•c Th·∫ßu ‚Äî‚Äî‚Äî
if option == "L·ªçc Danh M·ª•c Th·∫ßu":
    st.header("üìÇ L·ªçc Danh M·ª•c Th·∫ßu")

    # 1.1 Ch·ªçn Mi·ªÅn/V√πng/T·ªânh/BV
    df3 = st.session_state["file3"].copy()
    sel_region = st.selectbox("Mi·ªÅn", ["(T·∫•t c·∫£)"] + sorted(df3["Mi·ªÅn"].dropna().unique().tolist()))
    if sel_region != "(T·∫•t c·∫£)": df3 = df3[df3["Mi·ªÅn"] == sel_region]
    sel_area = st.selectbox("V√πng", ["(T·∫•t c·∫£)"] + sorted(df3["V√πng"].dropna().unique().tolist()))
    if sel_area != "(T·∫•t c·∫£)": df3 = df3[df3["V√πng"] == sel_area]
    sel_prov = st.selectbox("T·ªânh", ["(T·∫•t c·∫£)"] + sorted(df3["T·ªânh"].dropna().unique().tolist()))
    if sel_prov != "(T·∫•t c·∫£)": df3 = df3[df3["T·ªânh"] == sel_prov]
    sel_hospital = st.selectbox("BV/SYT", sorted(df3["B·ªánh vi·ªán/SYT"].dropna().unique().tolist()))

    # 1.2 T·∫£i file m·ªùi th·∫ßu
    uploaded = st.file_uploader("File M·ªùi Th·∫ßu (.xlsx)", type="xlsx")
    if uploaded is None:
        st.info("Vui l√≤ng t·∫£i l√™n file m·ªùi th·∫ßu.")
        st.stop()

    # 1.3 X√°c ƒë·ªãnh sheet v√† reader
    xls = pd.ExcelFile(uploaded)
    sheet = max(xls.sheet_names, key=lambda n: xls.parse(n, nrows=1, header=None).shape[1])
    raw = pd.read_excel(uploaded, sheet_name=sheet, header=None)

    # 1.4 T√¨m header row
    hdr_row = find_header_row(raw, HEADER_KEYS)
    if hdr_row is None:
        st.error("Kh√¥ng t√¨m th·∫•y header trong 10 d√≤ng ƒë·∫ßu.")
        st.stop()

    # 1.5 ƒê·ªçc DataFrame v·ªõi header
    header = raw.iloc[hdr_row].tolist()
    df = raw.iloc[hdr_row+1:].reset_index(drop=True)
    df.columns = header
    df = df.dropna(how="all").reset_index(drop=True)

    # 1.6 T·ª± t√¨m c·ªôt h√†m l∆∞·ª£ng
    conc_col = next(
        (c for c in df.columns if any(k in norm(c) for k in ["n·ªìng ƒë·ªô","h√†m l∆∞·ª£ng"])),
        None
    )
    if conc_col is None:
        st.error("Kh√¥ng t√¨m th·∫•y c·ªôt h√†m l∆∞·ª£ng.")
        st.stop()

    # 1.7 Chu·∫©n h√≥a keys cho merge
    df["_act"]  = df["T√™n ho·∫°t ch·∫•t"].apply(norm)
    df["_conc"] = df[conc_col].apply(norm)
    df["_grp"]  = df["Nh√≥m thu·ªëc"].astype(str).apply(lambda x: re.sub(r"\D", "", x))

    cmp = file2.copy()
    cmp["_act"]  = cmp["T√™n ho·∫°t ch·∫•t"].apply(norm)
    cmp["_conc"] = cmp["N·ªìng ƒë·ªô/H√†m l∆∞·ª£ng"].apply(norm)
    cmp["_grp"]  = cmp["Nh√≥m thu·ªëc"].astype(str).apply(lambda x: re.sub(r"\D","",x))

    # 1.8 Merge left gi·ªØ nguy√™n d√≤ng g·ªëc
    merged = pd.merge(df, cmp, on=["_act","_conc","_grp"], how="left", suffixes=("","_cmp"))

    # 1.9 G·∫Øn th√¥ng tin BV / Kh√°ch h√†ng
    info3 = df3[df3["B·ªánh vi·ªán/SYT"] == sel_hospital][
        ["T√™n s·∫£n ph·∫©m","ƒê·ªãa b√†n","T√™n Kh√°ch h√†ng ph·ª• tr√°ch tri·ªÉn khai"]
    ].drop_duplicates()
    merged = pd.merge(merged, info3, on="T√™n s·∫£n ph·∫©m", how="left")

    # 1.10 T√≠nh T·ª∑ tr·ªçng nh√≥m th·∫ßu (ch·ªâ nh√≥m N1‚ÄìN5)
    merged["S·ªë l∆∞·ª£ng"] = pd.to_numeric(merged.get("S·ªë l∆∞·ª£ng",0), errors="coerce").fillna(0)
    allow = [str(i) for i in range(1,6)]
    valid = merged["_grp"].isin(allow)
    grp_sum = merged[valid].groupby("Nh√≥m thu·ªëc")["S·ªë l∆∞·ª£ng"].transform("sum")
    merged["T·ª∑ tr·ªçng nh√≥m th·∫ßu"] = 0
    merged.loc[valid, "T·ª∑ tr·ªçng nh√≥m th·∫ßu"] = (
        merged.loc[valid,"S·ªë l∆∞·ª£ng"] / grp_sum
    ).fillna(0).apply(lambda x: f"{x:.2%}")

    # 1.11 L∆∞u session
    st.session_state["filtered_df"] = merged
    st.session_state["df_all"] = df

    # 1.12 Hi·ªÉn th·ªã k·∫øt qu·∫£
    st.success(f"‚úÖ ƒê√£ l·ªçc xong {len(merged)} d√≤ng (gi·ªØ nguy√™n g·ªëc).")
    display = merged.drop_duplicates(subset=["_act","_conc","_grp"])
    display = display[display["T√™n s·∫£n ph·∫©m"].notna()]
    st.dataframe(
        display[[
            "T√™n ho·∫°t ch·∫•t", conc_col, "Nh√≥m thu·ªëc",
            "T√™n s·∫£n ph·∫©m","ƒê·ªãa b√†n",
            "T√™n Kh√°ch h√†ng ph·ª• tr√°ch tri·ªÉn khai",
            "T·ª∑ tr·ªçng nh√≥m th·∫ßu"
        ]],
        height=500
    )

    # 1.13 Download full
    buf = BytesIO()
    merged.to_excel(buf, index=False, sheet_name="KetQuaLoc")
    st.download_button("‚¨áÔ∏è T·∫£i full k·∫øt qu·∫£", buf.getvalue(), "KetQuaLoc.xlsx")

# ‚Äî‚Äî‚Äî 2. Ph√¢n T√≠ch Danh M·ª•c Th·∫ßu ‚Äî‚Äî‚Äî
elif option == "Ph√¢n T√≠ch Danh M·ª•c Th·∫ßu":
    st.header("üìä Ph√¢n T√≠ch Danh M·ª•c Th·∫ßu")
    if "df_all" not in st.session_state:
        st.info("Ch·∫°y L·ªçc Danh M·ª•c Th·∫ßu tr∆∞·ªõc.")
        st.stop()

    dfA = st.session_state["df_all"].copy()
    dfA["S·ªë l∆∞·ª£ng"] = pd.to_numeric(dfA["S·ªë l∆∞·ª£ng"],errors="coerce").fillna(0)
    dfA["Gi√° k·∫ø ho·∫°ch"] = pd.to_numeric(dfA.get("Gi√° k·∫ø ho·∫°ch",0),errors="coerce").fillna(0)
    dfA["Tr·ªã gi√°"] = dfA["S·ªë l∆∞·ª£ng"] * dfA["Gi√° k·∫ø ho·∫°ch"]

    # Tra c·ª©u ho·∫°t ch·∫•t t√≠ch h·ª£p
    term = st.text_input("üîç Tra c·ª©u ho·∫°t ch·∫•t")
    if term:
        dfA = dfA[dfA["T√™n ho·∫°t ch·∫•t"].str.contains(term, case=False, na=False)]

    pd.options.display.float_format = "{:,.0f}".format
    def plot_bar(df, x, y, title):
        fig = px.bar(df, x=x, y=y, title=title)
        fig.update_traces(texttemplate="%{y:,.0f}", textposition="outside")
        st.plotly_chart(fig, use_container_width=True)

    # Tr·ªã gi√° theo Nh√≥m thu·ªëc
    g1 = dfA.groupby("Nh√≥m thu·ªëc")["Tr·ªã gi√°"].sum().reset_index().sort_values("Tr·ªã gi√°", ascending=False)
    plot_bar(g1, "Nh√≥m thu·ªëc", "Tr·ªã gi√°", "Tr·ªã gi√° theo Nh√≥m thu·ªëc")

    # Tr·ªã gi√° theo ƒê∆∞·ªùng d√πng
    dfA["ƒê∆∞·ªùng"] = dfA["ƒê∆∞·ªùng d√πng"].apply(
        lambda s: "Ti√™m" if "ti√™m" in str(s).lower() else ("U·ªëng" if "u·ªëng" in str(s).lower() else "Kh√°c")
    )
    g2 = dfA.groupby("ƒê∆∞·ªùng")["Tr·ªã gi√°"].sum().reset_index()
    plot_bar(g2, "ƒê∆∞·ªùng", "Tr·ªã gi√°", "Tr·ªã gi√° theo ƒê∆∞·ªùng d√πng")

    # Top 10 HC theo SL & Tr·ªã gi√°
    top_sl = dfA.groupby("T√™n ho·∫°t ch·∫•t")["S·ªë l∆∞·ª£ng"].sum().reset_index().sort_values("S·ªë l∆∞·ª£ng", ascending=False).head(10)
    top_v  = dfA.groupby("T√™n ho·∫°t ch·∫•t")["Tr·ªã gi√°"].sum().reset_index().sort_values("Tr·ªã gi√°", ascending=False).head(10)
    plot_bar(top_sl, "T√™n ho·∫°t ch·∫•t", "S·ªë l∆∞·ª£ng", "Top 10 Ho·∫°t ch·∫•t (SL)")
    plot_bar(top_v,  "T√™n ho·∫°t ch·∫•t", "Tr·ªã gi√°",  "Top 10 Ho·∫°t ch·∫•t (Tr·ªã gi√°)")

    # Ph√¢n t√≠ch Nh√≥m ƒëi·ªÅu tr·ªã
    treat_map = {norm(a):g for a,g in zip(file4["Ho·∫°t ch·∫•t"], file4["Nh√≥m ƒëi·ªÅu tr·ªã"])}
    dfA["Nh√≥m ƒëi·ªÅu tr·ªã"] = dfA["T√™n ho·∫°t ch·∫•t"].apply(lambda x: treat_map.get(norm(x), "Kh√°c"))
    t2 = dfA.groupby("Nh√≥m ƒëi·ªÅu tr·ªã")[["S·ªë l∆∞·ª£ng","Tr·ªã gi√°"]].sum().reset_index()
    plot_bar(t2.sort_values("S·ªë l∆∞·ª£ng",ascending=False), "Nh√≥m ƒëi·ªÅu tr·ªã","S·ªë l∆∞·ª£ng","SL theo Nh√≥m ƒëi·ªÅu tr·ªã")
    sel = st.selectbox("Ch·ªçn Nh√≥m ƒëi·ªÅu tr·ªã xem Top 10 HC (Tr·ªã gi√°)", t2["Nh√≥m ƒëi·ªÅu tr·ªã"].tolist())
    if sel:
        t3 = dfA[dfA["Nh√≥m ƒëi·ªÅu tr·ªã"]==sel].groupby("T√™n ho·∫°t ch·∫•t")["Tr·ªã gi√°"].sum().reset_index().sort_values("Tr·ªã gi√°",ascending=False).head(10)
        plot_bar(t3, "T√™n ho·∫°t ch·∫•t", "Tr·ªã gi√°", f"Top 10 HC tr·ªã gi√° - {sel}")

# ‚Äî‚Äî‚Äî 3. Ph√¢n T√≠ch Danh M·ª•c Tr√∫ng Th·∫ßu ‚Äî‚Äî‚Äî
elif option == "Ph√¢n T√≠ch Danh M·ª•c Tr√∫ng Th·∫ßu":
    st.header("üèÜ Ph√¢n T√≠ch Danh M·ª•c Tr√∫ng Th·∫ßu")
    win = st.file_uploader("File Tr√∫ng Th·∫ßu (.xlsx)", type="xlsx")
    if win is None:
        st.info("T·∫£i l√™n file tr√∫ng th·∫ßu tr∆∞·ªõc.")
        st.stop()

    xlsw = pd.ExcelFile(win)
    sheetw = max(xlsw.sheet_names, key=lambda n: xlsw.parse(n,nrows=1,header=None).shape[1])
    raww = pd.read_excel(win, sheet_name=sheetw, header=None)

    hw = find_header_row(raww, HEADER_KEYS + ["nh√† th·∫ßu"])
    if hw is None:
        st.error("Kh√¥ng t√¨m th·∫•y header tr√∫ng th·∫ßu.")
        st.stop()

    hdrw = raww.iloc[hw].tolist()
    dfw = raww.iloc[hw+1:].copy().reset_index(drop=True)
    dfw.columns = hdrw
    dfw = dfw.dropna(how="all").reset_index(drop=True)

    dfw["S·ªë l∆∞·ª£ng"] = pd.to_numeric(dfw.get("S·ªë l∆∞·ª£ng",0),errors="coerce").fillna(0)
    price_col = next((c for c in dfw.columns if "gi√° tr√∫ng" in norm(c)), "Gi√° k·∫ø ho·∫°ch")
    dfw[price_col] = pd.to_numeric(dfw.get(price_col,0),errors="coerce").fillna(0)
    dfw["Tr·ªã gi√°"] = dfw["S·ªë l∆∞·ª£ng"] * dfw[price_col]

    wv = dfw.groupby("Nh√† th·∫ßu tr√∫ng")["Tr·ªã gi√°"].sum().reset_index().sort_values("Tr·ªã gi√°",ascending=False).head(20)
    f1 = px.bar(wv, x="Tr·ªã gi√°", y="Nh√† th·∫ßu tr√∫ng", orientation="h", title="Top 20 Nh√† th·∫ßu tr√∫ng")
    f1.update_traces(texttemplate="%{x:,.0f}", textposition="outside")
    st.plotly_chart(f1, use_container_width=True)

    dfw["Nh√≥m ƒëi·ªÅu tr·ªã"] = dfw["T√™n ho·∫°t ch·∫•t"].apply(lambda x: treat_map.get(norm(x), "Kh√°c"))
    tw = dfw.groupby("Nh√≥m ƒëi·ªÅu tr·ªã")["Tr·ªã gi√°"].sum().reset_index()
    f2 = px.pie(tw, names="Nh√≥m ƒëi·ªÅu tr·ªã", values="Tr·ªã gi√°", title="C∆° c·∫•u tr·ªã gi√° tr√∫ng th·∫ßu")
    st.plotly_chart(f2, use_container_width=True)

# ‚Äî‚Äî‚Äî 4. ƒê·ªÅ Xu·∫•t H∆∞·ªõng Tri·ªÉn Khai ‚Äî‚Äî‚Äî
elif option == "ƒê·ªÅ Xu·∫•t H∆∞·ªõng Tri·ªÉn Khai":
    st.header("üí° ƒê·ªÅ Xu·∫•t H∆∞·ªõng Tri·ªÉn Khai")
    if "filtered_df" not in st.session_state:
        st.info("Ch·∫°y L·ªçc Danh M·ª•c Th·∫ßu tr∆∞·ªõc.")
        st.stop()

    dfm = st.session_state["filtered_df"].copy()
    # SL ƒë√£ l√†m
    done = dfm.groupby(["_act","_conc","_grp"])["S·ªë l∆∞·ª£ng"].sum().reset_index().rename(columns={"S·ªë l∆∞·ª£ng":"SL_ƒê√£ l√†m"})
    # SL y√™u c·∫ßu BV
    req = file3.copy()
    req["_act"]  = req["T√™n ho·∫°t ch·∫•t"].apply(norm)
    req["_conc"] = req[conc3].apply(norm) if conc3 else ""
    req["_grp"]  = req["Nh√≥m thu·ªëc"].astype(str).apply(lambda x: re.sub(r"\D","",x))
    req = req.groupby(["_act","_conc","_grp"])["S·ªë l∆∞·ª£ng"].sum().reset_index().rename(columns={"S·ªë l∆∞·ª£ng":"SL_Y√™u c·∫ßu"})
    # Merge & t√≠nh ƒë·ªÅ xu·∫•t
    sug = pd.merge(req, done, on=["_act","_conc","_grp"], how="left").fillna(0)
    sug["ƒê·ªÅ xu·∫•t"] = (sug["SL_Y√™u c·∫ßu"] - sug["SL_ƒê√£ l√†m"]).clip(lower=0).astype(int)
    # Th√™m kh√°ch h√†ng
    kh = file3.copy()
    kh["_act"]  = kh["T√™n ho·∫°t ch·∫•t"].apply(norm)
    kh["_conc"] = kh[conc3].apply(norm) if conc3 else ""
    kh["_grp"]  = kh["Nh√≥m thu·ªëc"].astype(str).apply(lambda x: re.sub(r"\D","",x))
    kh = kh.groupby(["_act","_conc","_grp"])["T√™n Kh√°ch h√†ng ph·ª• tr√°ch tri·ªÉn khai"].first().reset_index()
    sug = pd.merge(sug, kh, on=["_act","_conc","_grp"], how="left")

    st.dataframe(sug, height=500)
