import streamlit as st
import pandas as pd
import numpy as np
import re
import unicodedata
import requests
from io import BytesIO
import plotly.express as px

# ‚Äî‚Äî‚Äî‚Äî‚Äî Helper ‚Äî‚Äî‚Äî‚Äî‚Äî
def remove_accents(s):
    nfkd = unicodedata.normalize("NFKD", s)
    return "".join(c for c in nfkd if not unicodedata.combining(c))

def norm(s):
    s = remove_accents(str(s)).lower().strip()
    return re.sub(r"\s+", " ", s)

def find_header(df, keys):
    for i in range(10):
        row = " ".join(df.iloc[i].fillna("").astype(str)).lower()
        if all(k in row for k in keys):
            return i
    return None

@st.cache_data
def load_data():
    urls = {
        "file2":"https://raw.githubusercontent.com/phamtai1211/Thau_3PPharma/main/file2.xlsx",
        "file3":"https://raw.githubusercontent.com/phamtai1211/Thau_3PPharma/main/file3.xlsx",
        "file4":"https://raw.githubusercontent.com/phamtai1211/Thau_3PPharma/main/nhom_dieu_tri.xlsx"
    }
    f2 = pd.read_excel(BytesIO(requests.get(urls["file2"]).content))
    f3 = pd.read_excel(BytesIO(requests.get(urls["file3"]).content))
    f4 = pd.read_excel(BytesIO(requests.get(urls["file4"]).content))
    return f2, f3, f4

file2, file3, file4 = load_data()
# t√¨m c·ªôt h√†m l∆∞·ª£ng
conc_col = next((c for c in file3.columns if "n·ªìng ƒë·ªô" in c.lower()), None)

# ‚Äî‚Äî‚Äî l·ªçc file3 ‚Äî‚Äî‚Äî
file3["ƒê·ªãa b√†n"] = file3["ƒê·ªãa b√†n"].fillna("")
file3 = file3[~file3["ƒê·ªãa b√†n"].str.contains("t·∫°m ng∆∞ng tri·ªÉn khai|ko c√≥ ƒë·ªãa b√†n", case=False)]
st.session_state["file3"] = file3

# ‚Äî‚Äî‚Äî Sidebar ‚Äî‚Äî‚Äî
st.sidebar.title("Ch·ª©c nƒÉng")
opt = st.sidebar.radio("", [
    "L·ªçc Danh M·ª•c Th·∫ßu",
    "Ph√¢n T√≠ch Danh M·ª•c Th·∫ßu",
    "Ph√¢n T√≠ch Danh M·ª•c Tr√∫ng Th·∫ßu",
    "ƒê·ªÅ Xu·∫•t H∆∞·ªõng Tri·ªÉn Khai"
])

# ‚Äî‚Äî‚Äî 1. L·ªåC DANH M·ª§C ‚Äî‚Äî‚Äî
if opt=="L·ªçc Danh M·ª•c Th·∫ßu":
    st.header("üìÇ L·ªçc Danh M·ª•c Th·∫ßu")
    df3 = st.session_state["file3"].copy()
    # ch·ªçn Mi·ªÅn/V√πng/T·ªânh/BV
    r = st.selectbox("Mi·ªÅn", ["(T·∫•t c·∫£)"]+sorted(df3["Mi·ªÅn"].dropna().unique()))
    if r!="(T·∫•t c·∫£)": df3=df3[df3["Mi·ªÅn"]==r]
    a = st.selectbox("V√πng", ["(T·∫•t c·∫£)"]+sorted(df3["V√πng"].dropna().unique()))
    if a!="(T·∫•t c·∫£)": df3=df3[df3["V√πng"]==a]
    p = st.selectbox("T·ªânh", ["(T·∫•t c·∫£)"]+sorted(df3["T·ªânh"].dropna().unique()))
    if p!="(T·∫•t c·∫£)": df3=df3[df3["T·ªânh"]==p]
    h = st.selectbox("BV/SYT", sorted(df3["B·ªánh vi·ªán/SYT"].unique()))

    up = st.file_uploader("File m·ªùi th·∫ßu", type="xlsx")
    if not up:
        st.info("T·∫£i l√™n file tr∆∞·ªõc ƒë√£.")
        st.stop()

    xls = pd.ExcelFile(up)
    sheet = max(xls.sheet_names, key=lambda n: xls.parse(n,nrows=1,header=None).shape[1])
    raw = pd.read_excel(up, sheet_name=sheet, header=None)
    hdr = find_header(raw, ["t√™n ho·∫°t ch·∫•t","s·ªë l∆∞·ª£ng"])
    if hdr is None:
        st.error("Kh√¥ng t√¨m ƒë∆∞·ª£c header.")
        st.stop()
    cols = raw.iloc[hdr].tolist()
    df = raw.iloc[hdr+1:].copy().reset_index(drop=True)
    df.columns = cols
    df = df.dropna(how="all").reset_index(drop=True)

    # chu·∫©n h√≥a key
    df["_act"] = df["T√™n ho·∫°t ch·∫•t"].apply(norm)
    df["_conc"]= df[conc_col].apply(norm)
    df["_grp"]= df["Nh√≥m thu·ªëc"].astype(str).apply(lambda x:re.sub(r"\D","",x))

    c2 = file2.copy()
    c2["_act"]= c2["T√™n ho·∫°t ch·∫•t"].apply(norm)
    c2["_conc"]= c2["N·ªìng ƒë·ªô/H√†m l∆∞·ª£ng"].apply(norm)
    c2["_grp"]= c2["Nh√≥m thu·ªëc"].astype(str).apply(lambda x:re.sub(r"\D","",x))

    # merge left gi·ªØ nguy√™n d√≤ng g·ªëc
    m = pd.merge(df, c2, on=["_act","_conc","_grp"], how="left", suffixes=("","_cmp"))

    # g·∫Øn in4 BV/h√†ng h√≥a
    info = df3[df3["B·ªánh vi·ªán/SYT"]==h][["T√™n s·∫£n ph·∫©m","ƒê·ªãa b√†n","T√™n Kh√°ch h√†ng ph·ª• tr√°ch tri·ªÉn khai"]].drop_duplicates()
    m = pd.merge(m, info, on="T√™n s·∫£n ph·∫©m", how="left")

    # t√≠nh t·ª∑ tr·ªçng nh√≥m th·∫ßu (ch·ªâ 5 nh√≥m thu·ªëc c√≥ m·∫∑t)
    total_grp = m.groupby("Nh√≥m thu·ªëc")["S·ªë l∆∞·ª£ng"].transform("sum")
    m["T·ª∑ tr·ªçng nh√≥m th·∫ßu"] = (pd.to_numeric(m["S·ªë l∆∞·ª£ng"],errors="coerce").fillna(0)/total_grp).fillna(0).apply(lambda x:f"{x:.2%}")

    st.session_state["filtered"] = m
    st.session_state["df_all"] = df

    st.success(f"‚úÖ ƒê√£ l·ªçc xong {len(m)} d√≤ng.")
    # --- Hi·ªÉn th·ªã kh√¥ng tr√πng: drop duplicates theo key (_act, _conc, _grp) ---
    display = m.drop_duplicates(subset=["_act","_conc","_grp"]).copy()
    # Ch·ªâ show nh·ªØng d√≤ng c√≥ s·∫£n ph·∫©m (T√™n s·∫£n ph·∫©m kh√¥ng null)
    display = display[display["T√™n s·∫£n ph·∫©m"].notna()]
    st.dataframe(display, height=500)

    buf = BytesIO()
    m.to_excel(buf, index=False, sheet_name="KetQuaLoc")
    st.download_button("‚¨áÔ∏è T·∫£i v·ªÅ full k·∫øt qu·∫£", buf.getvalue(), "KetQuaLoc.xlsx")

# ‚Äî‚Äî‚Äî 2. PH√ÇN T√çCH DANH M·ª§C ‚Äî‚Äî‚Äî
elif opt=="Ph√¢n T√≠ch Danh M·ª•c Th·∫ßu":
    st.header("üìä Ph√¢n T√≠ch Danh M·ª•c Th·∫ßu")
    if "df_all" not in st.session_state:
        st.info("Ch·∫°y L·ªçc tr∆∞·ªõc.")
        st.stop()
    dfA = st.session_state["df_all"].copy()
    dfA["S·ªë l∆∞·ª£ng"]=pd.to_numeric(dfA["S·ªë l∆∞·ª£ng"],errors="coerce").fillna(0)
    dfA["Gi√° k·∫ø ho·∫°ch"]=pd.to_numeric(dfA.get("Gi√° k·∫ø ho·∫°ch",0),errors="coerce").fillna(0)
    dfA["Tr·ªã gi√°"]=dfA["S·ªë l∆∞·ª£ng"]*dfA["Gi√° k·∫ø ho·∫°ch"]

    # t√≠ch h·ª£p Tra c·ª©u
    term = st.text_input("Tra c·ª©u ho·∫°t ch·∫•t")
    if term:
        dfA = dfA[dfA["T√™n ho·∫°t ch·∫•t"].str.contains(term, case=False, na=False)]

    # format number
    pd.options.display.float_format = '{:,.0f}'.format

    def plot(df, x,y,title):
        fig=px.bar(df, x=x,y=y,title=title)
        fig.update_traces(texttemplate="%{y:,.0f}",textposition="outside")
        st.plotly_chart(fig,use_container_width=True)

    # Tr·ªã gi√° theo nh√≥m thu·ªëc
    gv = dfA.groupby("Nh√≥m thu·ªëc")["Tr·ªã gi√°"].sum().reset_index().sort_values("Tr·ªã gi√°",ascending=False)
    plot(gv,"Nh√≥m thu·ªëc","Tr·ªã gi√°","Tr·ªã gi√° theo Nh√≥m thu·ªëc")

    # Tr·ªã gi√° theo ƒê∆∞·ªùng d√πng
    dfA["ƒê∆∞·ªùng"]=dfA["ƒê∆∞·ªùng d√πng"].apply(lambda s:"Ti√™m" if "ti√™m" in str(s).lower() else("U·ªëng" if "u·ªëng" in str(s).lower() else "Kh√°c"))
    g2=dfA.groupby("ƒê∆∞·ªùng")["Tr·ªã gi√°"].sum().reset_index()
    plot(g2,"ƒê∆∞·ªùng","Tr·ªã gi√°","Tr·ªã gi√° theo ƒê∆∞·ªùng d√πng")

    # Top 10 HC theo SL & Tr·ªã gi√°
    top_sl = dfA.groupby("T√™n ho·∫°t ch·∫•t")["S·ªë l∆∞·ª£ng"].sum().reset_index().sort_values("S·ªë l∆∞·ª£ng",ascending=False).head(10)
    top_v  = dfA.groupby("T√™n ho·∫°t ch·∫•t")["Tr·ªã gi√°"].sum().reset_index().sort_values("Tr·ªã gi√°",ascending=False).head(10)
    plot(top_sl,"T√™n ho·∫°t ch·∫•t","S·ªë l∆∞·ª£ng","Top 10 HC theo SL")
    plot(top_v, "T√™n ho·∫°t ch·∫•t","Tr·ªã gi√°","Top 10 HC theo Tr·ªã gi√°")

    # Ph√¢n t√≠ch Nh√≥m ƒëi·ªÅu tr·ªã theo s·ªë l∆∞·ª£ng & tr·ªã gi√°
    treat = {norm(a):g for a,g in zip(file4["Ho·∫°t ch·∫•t"],file4["Nh√≥m ƒëi·ªÅu tr·ªã"])}
    dfA["Nh√≥m ƒëi·ªÅu tr·ªã"]=dfA["T√™n ho·∫°t ch·∫•t"].apply(lambda x:treat.get(norm(x),"Kh√°c"))
    t2 = dfA.groupby("Nh√≥m ƒëi·ªÅu tr·ªã")["S·ªë l∆∞·ª£ng"].sum().reset_index().sort_values("S·ªë l∆∞·ª£ng",ascending=False)
    plot(t2,"Nh√≥m ƒëi·ªÅu tr·ªã","S·ªë l∆∞·ª£ng","SL m·ªùi th·∫ßu theo Nh√≥m ƒëi·ªÅu tr·ªã")
    sel = st.selectbox("Ch·ªçn nh√≥m ƒëi·ªÅu tr·ªã xem Top 10 HC (Tr·ªã gi√°)", t2["Nh√≥m ƒëi·ªÅu tr·ªã"].tolist())
    if sel:
        t3 = dfA[dfA["Nh√≥m ƒëi·ªÅu tr·ªã"]==sel].groupby("T√™n ho·∫°t ch·∫•t")["Tr·ªã gi√°"].sum().reset_index().sort_values("Tr·ªã gi√°",ascending=False).head(10)
        plot(t3,"T√™n ho·∫°t ch·∫•t","Tr·ªã gi√°",f"Top 10 HC tr·ªã gi√° - {sel}")

# ‚Äî‚Äî‚Äî 3. PH√ÇN T√çCH TR√öNG TH·∫¶U ‚Äî‚Äî‚Äî
elif opt=="Ph√¢n T√≠ch Danh M·ª•c Tr√∫ng Th·∫ßu":
    st.header("üèÜ Ph√¢n T√≠ch Danh M·ª•c Tr√∫ng Th·∫ßu")
    win=st.file_uploader("File K·∫øt qu·∫£ Tr√∫ng Th·∫ßu",type="xlsx")
    if not win: st.info("T·∫£i file l√™n"); st.stop()
    xlsw=pd.ExcelFile(win)
    sh=max(xlsw.sheet_names,key=lambda n:xlsw.parse(n,nrows=1,header=None).shape[1])
    rw=pd.read_excel(win,sheet_name=sh,header=None)
    hi=find_header(rw,["t√™n ho·∫°t ch·∫•t","nh√† th·∫ßu tr√∫ng"])
    if hi is None: st.error("No header"); st.stop()
    hdr=rw.iloc[hi].tolist(); dfw=rw.iloc[hi+1:].reset_index(drop=True); dfw.columns=hdr; dfw=dfw.dropna(how="all")
    dfw["S·ªë l∆∞·ª£ng"]=pd.to_numeric(dfw.get("S·ªë l∆∞·ª£ng",0),errors="coerce").fillna(0)
    pc=next((c for c in dfw.columns if "Gi√° tr√∫ng" in c),"Gi√° k·∫ø ho·∫°ch")
    dfw[pc]=pd.to_numeric(dfw.get(pc,0),errors="coerce").fillna(0)
    dfw["Tr·ªã gi√°"]=dfw["S·ªë l∆∞·ª£ng"]*dfw[pc]
    wv=dfw.groupby("Nh√† th·∫ßu tr√∫ng")["Tr·ªã gi√°"].sum().reset_index().sort_values("Tr·ªã gi√°",ascending=False).head(20)
    f1=px.bar(wv,x="Tr·ªã gi√°",y="Nh√† th·∫ßu tr√∫ng",orientation="h",title="Top 20 Nh√† th·∫ßu"); f1.update_traces(texttemplate="%{x:,.0f}",textposition="outside"); st.plotly_chart(f1)
    dfw["Nh√≥m ƒëi·ªÅu tr·ªã"]=dfw["T√™n ho·∫°t ch·∫•t"].apply(lambda x:treat.get(norm(x),"Kh√°c"))
    tw=dfw.groupby("Nh√≥m ƒëi·ªÅu tr·ªã")["Tr·ªã gi√°"].sum().reset_index()
    f2=px.pie(tw,names="Nh√≥m ƒëi·ªÅu tr·ªã",values="Tr·ªã gi√°",title="C∆° c·∫•u tr√∫ng th·∫ßu"); st.plotly_chart(f2)

# ‚Äî‚Äî‚Äî 4. ƒê·ªÄ XU·∫§T H∆Ø·ªöNG TRI·ªÇN KHAI ‚Äî‚Äî‚Äî
elif opt=="ƒê·ªÅ Xu·∫•t H∆∞·ªõng Tri·ªÉn Khai":
    st.header("üí° ƒê·ªÅ Xu·∫•t H∆∞·ªõng Tri·ªÉn Khai")
    if "filtered" not in st.session_state:
        st.info("Ch·∫°y L·ªçc tr∆∞·ªõc."); st.stop()
    dfm=st.session_state["filtered"]
    # SL ƒë√£ th·ª±c hi·ªán
    done=dfm.groupby(["_act","_conc","_grp"])["S·ªë l∆∞·ª£ng"].sum().reset_index().rename(columns={"S·ªë l∆∞·ª£ng":"SL_ƒê√£ l√†m"})
    # SL y√™u c·∫ßu BV
    req=file3_filtered.copy()
    req["_act"]=req["T√™n ho·∫°t ch·∫•t"].apply(norm)
    req["_conc"]=req[conc_col].apply(norm)
    req["_grp"]=req["Nh√≥m thu·ªëc"].astype(str).apply(lambda x:re.sub(r"\D","",x))
    req=req.groupby(["_act","_conc","_grp"])["S·ªë l∆∞·ª£ng"].sum().reset_index().rename(columns={"S·ªë l∆∞·ª£ng":"SL_YeuCau"})
    # merge & t√≠nh ƒë·ªÅ xu·∫•t
    sug=pd.merge(req,done,on=["_act","_conc","_grp"],how="left").fillna(0)
    sug["ƒê·ªÅ xu·∫•t"]= (sug["SL_YeuCau"]-sug["SL_ƒê√£ l√†m"]).clip(lower=0).astype(int)
    # th√™m kh√°ch h√†ng ph·ª• tr√°ch
    kh=file3_filtered.copy()
    kh["_act"]=kh["T√™n ho·∫°t ch·∫•t"].apply(norm)
    kh["_conc"]=kh[conc_col].apply(norm)
    kh["_grp"]=kh["Nh√≥m thu·ªëc"].astype(str).apply(lambda x:re.sub(r"\D","",x))
    kh=kh.groupby(["_act","_conc","_grp"])["T√™n Kh√°ch h√†ng ph·ª• tr√°ch tri·ªÉn khai"].first().reset_index()
    sug=pd.merge(sug,kh,on=["_act","_conc","_grp"],how="left")
    st.dataframe(sug, height=500)
