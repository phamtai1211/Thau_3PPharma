import streamlit as st
import pandas as pd
import numpy as np
import re
import requests
import unicodedata
import zipfile
from io import BytesIO
from openpyxl import load_workbook
import plotly.express as px
from datetime import datetime

# === Load default data from GitHub ===
@st.cache_data
def load_default_data():
    urls = {
        'file2': "https://raw.githubusercontent.com/phamtai1211/Thau_3PPharma/main/file2.xlsx",
        'file3': "https://raw.githubusercontent.com/phamtai1211/Thau_3PPharma/main/file3.xlsx",
        'file4': "https://raw.githubusercontent.com/phamtai1211/Thau_3PPharma/main/nhom_dieu_tri.xlsx"
    }
    data = {}
    for key, url in urls.items():
        resp = requests.get(url)
        resp.raise_for_status()
        data[key] = pd.read_excel(BytesIO(resp.content), engine='openpyxl')
    return data['file2'], data['file3'], data['file4']

file2, file3, file4 = load_default_data()

# === Text normalization helpers ===
def remove_diacritics(s: str) -> str:
    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')

def normalize_text(s: str) -> str:
    s = str(s)
    s = remove_diacritics(s).lower()
    return re.sub(r'\s+', '', s)

def normalize_active(name: str) -> str:
    return re.sub(r'\s+', ' ', re.sub(r'\(.*?\)', '', str(name))).strip().lower()

def normalize_concentration(conc: str) -> str:
    s = str(conc).lower().replace(',', '.')
    parts = [p.strip() for p in re.split(r'[;,]', s) if p.strip()]
    parts = [p for p in parts if re.search(r'\d', p)]
    if len(parts) >= 2 and re.search(r'(mg|mcg|g|%)', parts[0]) and 'ml' in parts[-1]:
        return parts[0].replace(' ', '') + '/' + parts[-1].replace(' ', '')
    return ''.join(p.replace(' ', '') for p in parts)

def normalize_group(grp: str) -> str:
    return re.sub(r'\D', '', str(grp)).strip()

# === Process uploaded Excel files ===
def process_uploaded(uploaded, df3_temp):
    # Determine sheet with most columns
    xls = pd.ExcelFile(uploaded, engine='openpyxl')
    sheet = max(xls.sheet_names, key=lambda s: pd.read_excel(uploaded, sheet_name=s, nrows=5, header=None, engine='openpyxl').shape[1])
    try:
        raw = pd.read_excel(uploaded, sheet_name=sheet, header=None, engine='openpyxl')
    except Exception:
        uploaded.seek(0)
        buf = BytesIO(uploaded.read())
        zf = zipfile.ZipFile(buf, 'r')
        out = BytesIO()
        with zipfile.ZipFile(out, 'w') as w:
            for item in zf.infolist():
                if item.filename.startswith('xl/styles') or item.filename.startswith('xl/theme'):
                    continue
                data = zf.read(item.filename)
                if item.filename.startswith('xl/worksheets/'):
                    data = re.sub(b'<dataValidations.*?</dataValidations>', b'', data, flags=re.DOTALL)
                w.writestr(item.filename, data)
        out.seek(0)
        wb = load_workbook(out, read_only=True, data_only=True)
        ws = wb[sheet]
        raw = pd.DataFrame(list(ws.iter_rows(values_only=True)))

    # Auto-detect header row among first 10
    header_idx = None
    scores = []
    for i in range(min(10, len(raw))):
        text = normalize_text(' '.join(raw.iloc[i].fillna('').astype(str).tolist()))
        sc = sum(kw in text for kw in ['tenhoatchat','soluong','nhomthuoc','nongdo'])
        scores.append((i, sc))
        if 'tenhoatchat' in text and 'soluong' in text:
            header_idx = i
            break
    if header_idx is None:
        idx, sc = max(scores, key=lambda x: x[1])
        header_idx = idx if sc > 0 else 0

    header = raw.iloc[header_idx].fillna('').astype(str).tolist()
    df_body = raw.iloc[header_idx+1:].copy()
    df_body.columns = header
    df_body = df_body.dropna(subset=header, how='all')
    df_body['_orig_idx'] = df_body.index
    df_body.reset_index(drop=True, inplace=True)

    # Map to standard names
    col_map = {}
    for c in df_body.columns:
        n = normalize_text(c)
        if 'tenhoatchat' in n or 'tenthanhphan' in n:
            col_map[c] = 'TÃªn hoáº¡t cháº¥t'
        elif 'nongdo' in n or 'hamluong' in n:
            col_map[c] = 'Ná»“ng Ä‘á»™/hÃ m lÆ°á»£ng'
        elif ('nhom' in n and 'thuoc' in n) or (n.startswith('nhom') and len(n) <= 7):  # thÃªm dÃ²ng nÃ y
            col_map[c] = 'NhÃ³m thuá»‘c'
        elif 'soluong' in n:
            col_map[c] = 'Sá»‘ lÆ°á»£ng'
        elif 'duongdung' in n or 'duong' in n:
            col_map[c] = 'ÄÆ°á»ng dÃ¹ng'
        elif 'gia' in n:
            col_map[c] = 'GiÃ¡ káº¿ hoáº¡ch'
    df_body.rename(columns=col_map, inplace=True)

    # Prepare reference df2
    df2_norm = file2.copy()
    col_map2 = {}
    for c in df2_norm.columns:
        n = normalize_text(c)
        if 'tenhoatchat' in n:
            col_map2[c] = 'TÃªn hoáº¡t cháº¥t'
        elif 'nongdo' in n or 'hamluong' in n:
            col_map2[c] = 'Ná»“ng Ä‘á»™/hÃ m lÆ°á»£ng'
        elif 'nhom' in n and 'thuoc' in n:
            col_map2[c] = 'NhÃ³m thuá»‘c'
        elif 'tensanpham' in n:
            col_map2[c] = 'TÃªn sáº£n pháº©m'
    df2_norm.rename(columns=col_map2, inplace=True)

    # Add merge keys
    for df_ in (df_body, df2_norm):
        df_['active_norm'] = df_['TÃªn hoáº¡t cháº¥t'].apply(normalize_active)
        df_['conc_norm'] = df_['Ná»“ng Ä‘á»™/hÃ m lÆ°á»£ng'].apply(normalize_concentration)
        df_['group_norm'] = df_['NhÃ³m thuá»‘c'].apply(normalize_group)

    merged = pd.merge(df_body, df2_norm, on=['active_norm','conc_norm','group_norm'], how='left', indicator=True)
    merged.drop_duplicates(subset=['_orig_idx'], keep='first', inplace=True)

    hosp = df3_temp[['TÃªn sáº£n pháº©m','Äá»‹a bÃ n','TÃªn KhÃ¡ch hÃ ng phá»¥ trÃ¡ch triá»ƒn khai']]
    merged = pd.merge(merged, hosp, on='TÃªn sáº£n pháº©m', how='left')

    export_df = merged.drop(columns=['active_norm','conc_norm','group_norm','_merge','_orig_idx'])
    display_df = merged[merged['_merge']=='both'].drop(columns=['active_norm','conc_norm','group_norm','_merge','_orig_idx'])
    return display_df, export_df

# === Main UI ===
st.sidebar.title("Chá»©c nÄƒng")
option = st.sidebar.radio("Chá»n chá»©c nÄƒng", [
    "Lá»c Danh Má»¥c Tháº§u",
    "PhÃ¢n TÃ­ch Danh Má»¥c Tháº§u",
    "PhÃ¢n TÃ­ch Danh Má»¥c TrÃºng Tháº§u",
    "Äá» Xuáº¥t HÆ°á»›ng Triá»ƒn Khai"
])

# 1. Lá»c Danh Má»¥c Tháº§u
if option == "Lá»c Danh Má»¥c Tháº§u":
    st.header("ðŸ“‚ Lá»c Danh Má»¥c Tháº§u")
    df3_temp = file3.copy()
    for col in ['Miá»n','VÃ¹ng','Tá»‰nh','Bá»‡nh viá»‡n/SYT']:
        opts = ['(Táº¥t cáº£)'] + sorted(df3_temp[col].dropna().unique())
        sel = st.selectbox(f"Chá»n {col}", opts)
        if sel != '(Táº¥t cáº£)':
            df3_temp = df3_temp[df3_temp[col]==sel]
    uploaded = st.file_uploader("Táº£i lÃªn file Danh Má»¥c Má»i Tháº§u (.xlsx)", type=['xlsx'])
    if uploaded:
        display_df, export_df = process_uploaded(uploaded, df3_temp)
        st.success(f"âœ… Tá»•ng dÃ²ng khá»›p: {len(display_df)}")
        st.dataframe(display_df.fillna('').astype(str))
        # Save for analysis
        st.session_state['filtered_df'] = export_df.copy()
        st.session_state['selected_hospital'] = df3_temp['Bá»‡nh viá»‡n/SYT'].iloc[0] if 'Bá»‡nh viá»‡n/SYT' in df3_temp.columns else ''
        # Download filtered file with custom name
        buf = BytesIO()
        with pd.ExcelWriter(buf, engine='xlsxwriter') as writer:
            export_df.to_excel(writer, index=False, sheet_name='KetQuaLoc')
        today = datetime.now().strftime('%d.%m.%y')
        hospital = st.session_state.get('selected_hospital', '').replace('/', '-')
        filename = f"{today}-KQ Loc Thau - {hospital}.xlsx"
        st.download_button('â¬‡ï¸ Táº£i File Káº¿t Quáº£', data=buf.getvalue(), file_name=filename)

# 2. PhÃ¢n TÃ­ch Danh Má»¥c Tháº§u
elif option == "PhÃ¢n TÃ­ch Danh Má»¥c Tháº§u":
    st.header("ðŸ“Š PhÃ¢n TÃ­ch Danh Má»¥c Tháº§u")
    if 'filtered_df' not in st.session_state:
        st.info("Vui lÃ²ng thá»±c hiá»‡n bÆ°á»›c 'Lá»c Danh Má»¥c Tháº§u' trÆ°á»›c.")
    else:
        df = st.session_state['filtered_df'].copy()
        # Force rename to standard columns if misnamed
        rename_map = {}
        for c in df.columns:
            n = normalize_text(c)
            if 'nhom' in n and 'thuoc' in n:
                rename_map[c] = 'NhÃ³m thuá»‘c'
            if 'trigia' in n or (n.startswith('tri') and 'gia' in n):
                rename_map[c] = 'Trá»‹ giÃ¡'
        if rename_map:
            df.rename(columns=rename_map, inplace=True)
        df['Sá»‘ lÆ°á»£ng'] = pd.to_numeric(df.get('Sá»‘ lÆ°á»£ng', 0), errors='coerce').fillna(0)
        df['GiÃ¡ káº¿ hoáº¡ch'] = pd.to_numeric(df.get('GiÃ¡ káº¿ hoáº¡ch', 0), errors='coerce').fillna(0)
        df['Trá»‹ giÃ¡'] = df['Sá»‘ lÆ°á»£ng'] * df['GiÃ¡ káº¿ hoáº¡ch']
        # Chart 1: Trá»‹ giÃ¡ theo NhÃ³m thuá»‘c
        grp_val = df.groupby('NhÃ³m thuá»‘c')['Trá»‹ giÃ¡'].sum().reset_index().sort_values('Trá»‹ giÃ¡', False)
        fig1 = px.bar(grp_val, x='NhÃ³m thuá»‘c', y='Trá»‹ giÃ¡', title='Trá»‹ giÃ¡ theo NhÃ³m thuá»‘c')
        st.plotly_chart(fig1, use_container_width=True)
        # Chart 2: Tá»· trá»ng trá»‹ giÃ¡ theo Ä‘Æ°á»ng dÃ¹ng
        df['Loáº¡i Ä‘Æ°á»ng dÃ¹ng'] = df['ÄÆ°á»ng dÃ¹ng'].apply(lambda x: 'TiÃªm' if 'tiÃªm' in str(x).lower() else ('Uá»‘ng' if 'uá»‘ng' in str(x).lower() else 'KhÃ¡c'))
        route_val = df.groupby('Loáº¡i Ä‘Æ°á»ng dÃ¹ng')['Trá»‹ giÃ¡'].sum().reset_index()
        fig2 = px.pie(route_val, names='Loáº¡i Ä‘Æ°á»ng dÃ¹ng', values='Trá»‹ giÃ¡', title='Tá»· trá»ng trá»‹ giÃ¡ theo Ä‘Æ°á»ng dÃ¹ng')
        st.plotly_chart(fig2, use_container_width=True)
        # Chart 3 & 4: Top 10 hoáº¡t cháº¥t theo SL vÃ  TG
        top_qty = df.groupby('TÃªn hoáº¡t cháº¥t')['Sá»‘ lÆ°á»£ng'].sum().reset_index().sort_values('Sá»‘ lÆ°á»£ng', False).head(10)
        fig3 = px.bar(top_qty, x='TÃªn hoáº¡t cháº¥t', y='Sá»‘ lÆ°á»£ng', title='Top 10 Hoáº¡t cháº¥t (SL)')
        st.plotly_chart(fig3, use_container_width=True)
        top_val = df.groupby('TÃªn hoáº¡t cháº¥t')['Trá»‹ giÃ¡'].sum().reset_index().sort_values('Trá»‹ giÃ¡', False).head(10)
        fig4 = px.bar(top_val, x='TÃªn hoáº¡t cháº¥t', y='Trá»‹ giÃ¡', title='Top 10 Hoáº¡t cháº¥t (TG)')
        st.plotly_chart(fig4, use_container_width=True)
        # Chart 5: Trá»‹ giÃ¡ theo NhÃ³m Ä‘iá»u trá»‹
        treat_map = {normalize_active(a): grp for a, grp in zip(file4['Hoáº¡t cháº¥t'], file4['NhÃ³m Ä‘iá»u trá»‹'])}
        df['NhÃ³m Ä‘iá»u trá»‹'] = df['TÃªn hoáº¡t cháº¥t'].apply(lambda x: treat_map.get(normalize_active(x), 'KhÃ¡c'))
        treat_val = df.groupby('NhÃ³m Ä‘iá»u trá»‹')['Trá»‹ giÃ¡'].sum().reset_index().sort_values('Trá»‹ giÃ¡', False)
        fig5 = px.bar(treat_val, x='Trá»‹ giÃ¡', y='NhÃ³m Ä‘iá»u trá»‹', orientation='h', title='Trá»‹ giÃ¡ theo NhÃ³m Ä‘iá»u trá»‹')
        st.plotly_chart(fig5, use_container_width=True)
        sel_grp = st.selectbox('Chá»n nhÃ³m Ä‘á»ƒ xem Top 10 sáº£n pháº©m', treat_val['NhÃ³m Ä‘iá»u trá»‹'].tolist())
        if sel_grp:
            top_prod = df[df['NhÃ³m Ä‘iá»u trá»‹']==sel_grp].groupby('TÃªn sáº£n pháº©m')['Trá»‹ giÃ¡'].sum().reset_index().sort_values('Trá»‹ giÃ¡', False).head(10)
            fig6 = px.bar(top_prod, x='Trá»‹ giÃ¡', y='TÃªn sáº£n pháº©m', orientation='h', title=f'Top 10 sáº£n pháº©m - NhÃ³m {sel_grp}')
            st.plotly_chart(fig6, use_container_width=True)
        # Chart 6: Trá»‹ giÃ¡ theo KhÃ¡ch hÃ ng
        rep_val = df.groupby('TÃªn KhÃ¡ch hÃ ng phá»¥ trÃ¡ch triá»ƒn khai')['Trá»‹ giÃ¡'].sum().reset_index().sort_values('Trá»‹ giÃ¡', False)
        fig7 = px.bar(rep_val, x='Trá»‹ giÃ¡', y='TÃªn KhÃ¡ch hÃ ng phá»¥ trÃ¡ch triá»ƒn khai', orientation='h', title='Trá»‹ giÃ¡ theo KhÃ¡ch hÃ ng phá»¥ trÃ¡ch')
        st.plotly_chart(fig7, use_container_width=True)

# 3. PhÃ¢n TÃ­ch Danh Má»¥c TrÃºng Tháº§u
elif option == "PhÃ¢n TÃ­ch Danh Má»¥c TrÃºng Tháº§u":
    st.header("ðŸ† PhÃ¢n TÃ­ch Danh Má»¥c TrÃºng Tháº§u")
    st.info("Chá»©c nÄƒng Ä‘ang xÃ¢y dá»±ng...")

# 4. Äá» Xuáº¥t HÆ°á»›ng Triá»ƒn Khai
elif option == "Äá» Xuáº¥t HÆ°á»›ng Triá»ƒn Khai":
    st.header("ðŸ’¡ Äá» Xuáº¥t HÆ°á»›ng Triá»ƒn Khai")
    st.info("Chá»©c nÄƒng Ä‘ang xÃ¢y dá»±ng...")
